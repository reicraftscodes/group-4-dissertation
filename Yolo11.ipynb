{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qGNy4mtLiNbE",
        "outputId": "a5789b76-fece-4b00-9bdd-0e7c9f847faa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5OO6_7ubiOJQ",
        "outputId": "78b5f5a9-a291-434b-cd67-829735c6c7b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/YOLO11\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/YOLO11"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "5NIPhU4MiT2Z",
        "outputId": "e0f62e13-4459-41ff-fc58-d0120649c2d7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/YOLO11'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lCfFcsPiib4k",
        "outputId": "cffbf87c-aad2-4e65-9e42-34d9335b790f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ultralytics>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_yolo11.txt (line 5)) (8.3.191)\n",
            "Requirement already satisfied: mediapipe>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_yolo11.txt (line 8)) (0.10.21)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_yolo11.txt (line 11)) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.15.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_yolo11.txt (line 12)) (0.23.0+cu126)\n",
            "Requirement already satisfied: opencv-python>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_yolo11.txt (line 15)) (4.11.0.86)\n",
            "Requirement already satisfied: Pillow>=9.0.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_yolo11.txt (line 16)) (11.3.0)\n",
            "Requirement already satisfied: numpy>=1.24.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_yolo11.txt (line 19)) (1.26.4)\n",
            "Requirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_yolo11.txt (line 20)) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_yolo11.txt (line 23)) (1.6.1)\n",
            "Requirement already satisfied: matplotlib>=3.7.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_yolo11.txt (line 26)) (3.10.0)\n",
            "Requirement already satisfied: seaborn>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_yolo11.txt (line 27)) (0.13.2)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_yolo11.txt (line 30)) (4.67.1)\n",
            "Requirement already satisfied: PyYAML>=6.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_yolo11.txt (line 33)) (6.0.2)\n",
            "Requirement already satisfied: pathlib in /usr/local/lib/python3.12/dist-packages (from -r requirements_yolo11.txt (line 36)) (1.0.1)\n",
            "Requirement already satisfied: tensorboard>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_yolo11.txt (line 39)) (2.19.0)\n",
            "Requirement already satisfied: albumentations>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_yolo11.txt (line 40)) (2.0.8)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics>=8.0.0->-r requirements_yolo11.txt (line 5)) (2.32.4)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics>=8.0.0->-r requirements_yolo11.txt (line 5)) (1.16.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from ultralytics>=8.0.0->-r requirements_yolo11.txt (line 5)) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.12/dist-packages (from ultralytics>=8.0.0->-r requirements_yolo11.txt (line 5)) (9.0.0)\n",
            "Requirement already satisfied: polars in /usr/local/lib/python3.12/dist-packages (from ultralytics>=8.0.0->-r requirements_yolo11.txt (line 5)) (1.25.2)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics>=8.0.0->-r requirements_yolo11.txt (line 5)) (2.0.16)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from mediapipe>=0.10.0->-r requirements_yolo11.txt (line 8)) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.12/dist-packages (from mediapipe>=0.10.0->-r requirements_yolo11.txt (line 8)) (25.3.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.12/dist-packages (from mediapipe>=0.10.0->-r requirements_yolo11.txt (line 8)) (25.2.10)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.12/dist-packages (from mediapipe>=0.10.0->-r requirements_yolo11.txt (line 8)) (0.5.3)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.12/dist-packages (from mediapipe>=0.10.0->-r requirements_yolo11.txt (line 8)) (0.5.3)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.12/dist-packages (from mediapipe>=0.10.0->-r requirements_yolo11.txt (line 8)) (4.11.0.86)\n",
            "Requirement already satisfied: protobuf<5,>=4.25.3 in /usr/local/lib/python3.12/dist-packages (from mediapipe>=0.10.0->-r requirements_yolo11.txt (line 8)) (4.25.8)\n",
            "Requirement already satisfied: sounddevice>=0.4.4 in /usr/local/lib/python3.12/dist-packages (from mediapipe>=0.10.0->-r requirements_yolo11.txt (line 8)) (0.5.2)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (from mediapipe>=0.10.0->-r requirements_yolo11.txt (line 8)) (0.2.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements_yolo11.txt (line 11)) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements_yolo11.txt (line 11)) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements_yolo11.txt (line 11)) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements_yolo11.txt (line 11)) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements_yolo11.txt (line 11)) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements_yolo11.txt (line 11)) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements_yolo11.txt (line 11)) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements_yolo11.txt (line 11)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements_yolo11.txt (line 11)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements_yolo11.txt (line 11)) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements_yolo11.txt (line 11)) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements_yolo11.txt (line 11)) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements_yolo11.txt (line 11)) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements_yolo11.txt (line 11)) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements_yolo11.txt (line 11)) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements_yolo11.txt (line 11)) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements_yolo11.txt (line 11)) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements_yolo11.txt (line 11)) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements_yolo11.txt (line 11)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements_yolo11.txt (line 11)) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements_yolo11.txt (line 11)) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements_yolo11.txt (line 11)) (3.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.0->-r requirements_yolo11.txt (line 20)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.0->-r requirements_yolo11.txt (line 20)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.0->-r requirements_yolo11.txt (line 20)) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.3.0->-r requirements_yolo11.txt (line 23)) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.3.0->-r requirements_yolo11.txt (line 23)) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.0->-r requirements_yolo11.txt (line 26)) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.0->-r requirements_yolo11.txt (line 26)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.0->-r requirements_yolo11.txt (line 26)) (4.59.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.0->-r requirements_yolo11.txt (line 26)) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.0->-r requirements_yolo11.txt (line 26)) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.0->-r requirements_yolo11.txt (line 26)) (3.2.3)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.13.0->-r requirements_yolo11.txt (line 39)) (1.74.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.13.0->-r requirements_yolo11.txt (line 39)) (3.8.2)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.13.0->-r requirements_yolo11.txt (line 39)) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.13.0->-r requirements_yolo11.txt (line 39)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.13.0->-r requirements_yolo11.txt (line 39)) (3.1.3)\n",
            "Requirement already satisfied: pydantic>=2.9.2 in /usr/local/lib/python3.12/dist-packages (from albumentations>=1.3.0->-r requirements_yolo11.txt (line 40)) (2.11.7)\n",
            "Requirement already satisfied: albucore==0.0.24 in /usr/local/lib/python3.12/dist-packages (from albumentations>=1.3.0->-r requirements_yolo11.txt (line 40)) (0.0.24)\n",
            "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /usr/local/lib/python3.12/dist-packages (from albumentations>=1.3.0->-r requirements_yolo11.txt (line 40)) (4.11.0.86)\n",
            "Requirement already satisfied: stringzilla>=3.10.4 in /usr/local/lib/python3.12/dist-packages (from albucore==0.0.24->albumentations>=1.3.0->-r requirements_yolo11.txt (line 40)) (3.12.6)\n",
            "Requirement already satisfied: simsimd>=5.9.2 in /usr/local/lib/python3.12/dist-packages (from albucore==0.0.24->albumentations>=1.3.0->-r requirements_yolo11.txt (line 40)) (6.5.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.9.2->albumentations>=1.3.0->-r requirements_yolo11.txt (line 40)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.9.2->albumentations>=1.3.0->-r requirements_yolo11.txt (line 40)) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.9.2->albumentations>=1.3.0->-r requirements_yolo11.txt (line 40)) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics>=8.0.0->-r requirements_yolo11.txt (line 5)) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics>=8.0.0->-r requirements_yolo11.txt (line 5)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics>=8.0.0->-r requirements_yolo11.txt (line 5)) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics>=8.0.0->-r requirements_yolo11.txt (line 5)) (2025.8.3)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.12/dist-packages (from sounddevice>=0.4.4->mediapipe>=0.10.0->-r requirements_yolo11.txt (line 8)) (1.17.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->-r requirements_yolo11.txt (line 11)) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.13.0->-r requirements_yolo11.txt (line 39)) (3.0.2)\n",
            "Requirement already satisfied: ml_dtypes>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from jax->mediapipe>=0.10.0->-r requirements_yolo11.txt (line 8)) (0.5.3)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.12/dist-packages (from jax->mediapipe>=0.10.0->-r requirements_yolo11.txt (line 8)) (3.4.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe>=0.10.0->-r requirements_yolo11.txt (line 8)) (2.22)\n"
          ]
        }
      ],
      "source": [
        "!pip install -r requirements_yolo11.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVWqVS-AjpzW",
        "outputId": "ecbc2e23-6995-418d-d025-4c082678777f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file âœ… \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1756612900.257072   14094 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1756612900.263541   14094 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1756612900.280176   14094 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1756612900.280208   14094 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1756612900.280212   14094 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1756612900.280215   14094 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "============================================================\n",
            "TESTING DATASET FOR YOLO11 CONVERSION\n",
            "============================================================\n",
            "âœ… RGB: 3187 images\n",
            "âœ… Thermal: 3187 images\n",
            "âœ… RgbAug: 16542 images\n",
            "âœ… ThermalAug: 16542 images\n",
            "\n",
            "âœ… Dataset looks good for YOLO11 conversion!\n",
            "ğŸ“ Found 4 valid folders\n"
          ]
        }
      ],
      "source": [
        "# # 2. Test dataset (already done âœ…)\n",
        "!python main_yolo11.py --test-dataset --dataset-root \"/content/drive/MyDrive/data\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3OnhPOaZOcaz",
        "outputId": "43907f13-fea5-41be-ea8e-5fa96bd0d450"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1756316300.617808   42159 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1756316300.624434   42159 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1756316300.642831   42159 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1756316300.642865   42159 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1756316300.642868   42159 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1756316300.642871   42159 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "============================================================\n",
            "CONVERTING EMOTION DATASET TO YOLO FORMAT\n",
            "============================================================\n",
            "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "W0000 00:00:1756316303.566891   42224 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
            "Converting 4133 images from RGB...\n",
            "  Progress: 1000/4133 files processed...\n",
            "  Progress: 2000/4133 files processed...\n",
            "  Progress: 3000/4133 files processed...\n",
            "  Progress: 4000/4133 files processed...\n",
            "âœ… Converted 4133 files, skipped 0 files from RGB\n",
            "Converting 16542 images from RgbAug...\n",
            "  Progress: 1000/16542 files processed...\n",
            "  Progress: 2000/16542 files processed...\n",
            "  Progress: 3000/16542 files processed...\n",
            "  Progress: 4000/16542 files processed...\n",
            "  Progress: 5000/16542 files processed...\n",
            "  Progress: 6000/16542 files processed...\n",
            "  Progress: 7000/16542 files processed...\n",
            "  Progress: 8000/16542 files processed...\n",
            "  Progress: 9000/16542 files processed...\n",
            "  Progress: 10000/16542 files processed...\n",
            "  Progress: 11000/16542 files processed...\n",
            "  Progress: 12000/16542 files processed...\n",
            "  Progress: 13000/16542 files processed...\n",
            "  Progress: 14000/16542 files processed...\n",
            "  Progress: 15000/16542 files processed...\n",
            "  Progress: 16000/16542 files processed...\n",
            "âœ… Converted 16542 files, skipped 0 files from RgbAug\n",
            "Total converted files: 20675\n",
            "Dataset split: 13232 train, 3308 val, 4135 test\n",
            "Created YOLO data configuration: yolo_emotion_dataset/data.yaml\n",
            "\n",
            "âœ… Dataset conversion completed!\n",
            "ğŸ“ Output directory: yolo_emotion_dataset\n",
            "ğŸ“„ Data configuration: yolo_emotion_dataset/data.yaml\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/test/main_yolo11.py\", line 271, in <module>\n",
            "    main()\n",
            "  File \"/content/drive/MyDrive/test/main_yolo11.py\", line 254, in main\n",
            "    convert_dataset_command(config, args)\n",
            "  File \"/content/drive/MyDrive/test/main_yolo11.py\", line 38, in convert_dataset_command\n",
            "    data_yaml_path = convert_emotion_dataset_to_yolo(\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/test/yolo_dataset_converter.py\", line 383, in convert_emotion_dataset_to_yolo\n",
            "    return converter.create_yolo_dataset(Path(output_dir), modalities)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/test/yolo_dataset_converter.py\", line 306, in create_yolo_dataset\n",
            "    print(f\"ğŸ“Š Total converted files: {total_converted}\")\n",
            "                                       ^^^^^^^^^^^^^^^\n",
            "NameError: name 'total_converted' is not defined\n"
          ]
        }
      ],
      "source": [
        "# 3. Convert dataset RGB Only\n",
        "!python main_yolo11.py --convert --modality rgb_only --dataset-root \"/content/drive/MyDrive/data\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kG8D9O41j7A3",
        "outputId": "cafdadc4-ec61-4a8f-a74c-c6db744976c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1756612997.964460   14564 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1756612997.971001   14564 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1756612997.988093   14564 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1756612997.988128   14564 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1756612997.988131   14564 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1756612997.988134   14564 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "============================================================\n",
            "TRAINING YOLO11 FOR EMOTION DETECTION (RGB_ONLY)\n",
            "============================================================\n",
            "Initialized RGB-only YOLO11 model (n)\n",
            "YOLO11 Trainer initialized for rgb_only\n",
            "Device: cuda\n",
            "\n",
            "Starting YOLO11 training for rgb_only\n",
            "============================================================\n",
            "Training parameters:\n",
            "  Data config: yolo_emotion_dataset/data.yaml\n",
            "  Epochs: 30\n",
            "  Batch size: 16\n",
            "  Image size: 640\n",
            "  Device: cuda\n",
            "Ultralytics 8.3.189 ğŸš€ Python-3.12.11 torch-2.8.0+cu126 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=yolo_emotion_dataset/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=30, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo11n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train4, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs/detect/train4, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% â”â”â”â”â”â”â”â”â”â”â”â” 755.1/755.1KB 18.5MB/s 0.0s\n",
            "Overriding model.yaml nc=80 with nc=7\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
            "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
            "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
            " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
            " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
            " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
            " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
            " 23        [16, 19, 22]  1    432037  ultralytics.nn.modules.head.Detect           [7, [64, 128, 256]]           \n",
            "YOLO11n summary: 181 layers, 2,591,205 parameters, 2,591,189 gradients, 6.4 GFLOPs\n",
            "\n",
            "Transferred 448/499 items from pretrained weights\n",
            "Freezing layer 'model.23.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 175.5Â±205.3 ms, read: 0.0Â±0.0 MB/s, size: 12.5 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/test/yolo_emotion_dataset/train/labels.cache... 16843 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 16843/16843 154922505.0it/s 0.0s\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.4Â±0.2 ms, read: 0.0Â±0.0 MB/s, size: 10.4 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/test/yolo_emotion_dataset/val/labels.cache... 5550 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5550/5550 42401433.9it/s 0.0s\n",
            "Plotting labels to runs/detect/train4/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000909, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train4\u001b[0m\n",
            "Starting training for 30 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       1/30      2.28G      1.012      2.465      1.157         19        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1053/1053 0.69it/s 25:28\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 174/174 5.6it/s 31.1s\n",
            "                   all       5550       5550      0.404      0.567      0.459      0.336\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       2/30      2.62G     0.8719      1.401      1.045         15        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1053/1053 8.8it/s 1:59\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 174/174 7.4it/s 23.4s\n",
            "                   all       5550       5550      0.495      0.578      0.609      0.488\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       3/30      2.63G     0.8367      1.169       1.04         10        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1053/1053 8.9it/s 1:58\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 174/174 7.5it/s 23.2s\n",
            "                   all       5550       5550      0.634      0.582      0.638      0.524\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       4/30      2.65G     0.8071       1.06      1.033         21        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1053/1053 9.0it/s 1:57\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 174/174 7.5it/s 23.3s\n",
            "                   all       5550       5550      0.709       0.67       0.75       0.61\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       5/30      2.65G     0.7787     0.9665      1.025         21        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1053/1053 9.0it/s 1:56\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 174/174 7.4it/s 23.5s\n",
            "                   all       5550       5550      0.761      0.713      0.798      0.666\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       6/30      2.65G     0.7532     0.8846      1.017         19        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1053/1053 9.0it/s 1:57\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 174/174 7.5it/s 23.2s\n",
            "                   all       5550       5550      0.769      0.698      0.795      0.669\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       7/30      2.65G     0.7429     0.8403      1.013         25        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1053/1053 9.0it/s 1:57\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 174/174 7.5it/s 23.1s\n",
            "                   all       5550       5550       0.82      0.763      0.858       0.72\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       8/30      2.65G     0.7317     0.7845      1.013         19        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1053/1053 9.0it/s 1:57\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 174/174 7.4it/s 23.5s\n",
            "                   all       5550       5550      0.858       0.78      0.892      0.753\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       9/30      2.65G     0.7141     0.7511      1.002         20        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1053/1053 9.1it/s 1:56\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 174/174 7.5it/s 23.1s\n",
            "                   all       5550       5550      0.877      0.831      0.922      0.788\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      10/30      2.65G     0.7036     0.7189      1.001         13        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1053/1053 9.0it/s 1:57\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 174/174 7.4it/s 23.5s\n",
            "                   all       5550       5550      0.904      0.819      0.927      0.795\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      11/30      2.65G     0.6874     0.6832      0.993         21        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1053/1053 9.0it/s 1:57\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 174/174 7.5it/s 23.2s\n",
            "                   all       5550       5550      0.899      0.857      0.938      0.811\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      12/30      2.65G     0.6817     0.6576      0.989         14        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1053/1053 9.0it/s 1:57\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 174/174 7.6it/s 23.0s\n",
            "                   all       5550       5550      0.915      0.885      0.956      0.823\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      13/30      2.65G     0.6715     0.6338     0.9836         23        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1053/1053 9.0it/s 1:57\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 174/174 7.5it/s 23.1s\n",
            "                   all       5550       5550      0.931      0.881       0.96      0.834\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      14/30      2.65G     0.6719     0.6244     0.9853         26        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1053/1053 9.0it/s 1:57\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 174/174 7.6it/s 22.8s\n",
            "                   all       5550       5550      0.968      0.863      0.968      0.841\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      15/30      2.65G     0.6619     0.5975      0.982         16        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1053/1053 9.0it/s 1:57\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 174/174 7.5it/s 23.1s\n",
            "                   all       5550       5550      0.942      0.912      0.975      0.851\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      16/30      2.65G     0.6551     0.5771     0.9776         21        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1053/1053 9.0it/s 1:57\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 174/174 7.4it/s 23.5s\n",
            "                   all       5550       5550      0.947      0.918      0.974       0.85\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      17/30      2.65G     0.6501     0.5586     0.9742         24        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1053/1053 9.0it/s 1:57\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 174/174 7.5it/s 23.3s\n",
            "                   all       5550       5550      0.942      0.943      0.979      0.859\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      18/30      2.65G      0.638     0.5452     0.9692         18        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1053/1053 9.0it/s 1:57\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 174/174 7.5it/s 23.1s\n",
            "                   all       5550       5550       0.97      0.941      0.984      0.864\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      19/30      2.65G     0.6326     0.5255     0.9679         19        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1053/1053 9.0it/s 1:57\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 174/174 7.5it/s 23.2s\n",
            "                   all       5550       5550      0.967       0.95      0.986      0.869\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      20/30      2.65G     0.6248     0.5098     0.9651         29        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1053/1053 9.0it/s 1:57\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 174/174 7.5it/s 23.2s\n",
            "                   all       5550       5550      0.977      0.946      0.987      0.872\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      21/30      2.65G     0.5628     0.3412      0.943         11        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1053/1053 9.0it/s 1:57\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 174/174 7.4it/s 23.4s\n",
            "                   all       5550       5550       0.98      0.946      0.989      0.875\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      22/30      2.65G     0.5508     0.3158     0.9378         11        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1053/1053 9.1it/s 1:55\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 174/174 7.5it/s 23.3s\n",
            "                   all       5550       5550      0.975      0.964      0.992      0.881\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      23/30      2.65G     0.5442     0.3015     0.9322         11        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1053/1053 9.1it/s 1:56\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 174/174 7.5it/s 23.2s\n",
            "                   all       5550       5550      0.977      0.972      0.991       0.88\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      24/30      2.65G     0.5347     0.2904     0.9252         11        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1053/1053 9.1it/s 1:56\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 174/174 7.5it/s 23.2s\n",
            "                   all       5550       5550      0.982      0.975      0.993      0.887\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      25/30      2.65G     0.5265     0.2754     0.9235         11        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1053/1053 9.1it/s 1:55\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 174/174 7.5it/s 23.1s\n",
            "                   all       5550       5550      0.978      0.984      0.993      0.888\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      26/30      2.65G       0.52      0.263     0.9171         11        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1053/1053 9.1it/s 1:56\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 174/174 7.6it/s 22.9s\n",
            "                   all       5550       5550      0.987      0.987      0.994      0.891\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      27/30      2.65G      0.512     0.2527     0.9151         11        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1053/1053 9.2it/s 1:55\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 174/174 7.5it/s 23.2s\n",
            "                   all       5550       5550       0.99      0.985      0.994      0.896\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      28/30      2.65G     0.5048     0.2394     0.9119         11        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1053/1053 9.1it/s 1:56\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 174/174 7.7it/s 22.7s\n",
            "                   all       5550       5550      0.988      0.992      0.994      0.894\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      29/30      2.65G     0.4965     0.2313     0.9096         11        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1053/1053 9.2it/s 1:55\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 174/174 7.7it/s 22.7s\n",
            "                   all       5550       5550      0.989      0.992      0.994      0.897\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      30/30      2.65G       0.49     0.2248     0.9062         11        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1053/1053 9.1it/s 1:56\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 174/174 7.5it/s 23.3s\n",
            "                   all       5550       5550      0.994      0.989      0.994      0.898\n",
            "\n",
            "30 epochs completed in 1.563 hours.\n",
            "Optimizer stripped from runs/detect/train4/weights/last.pt, 5.5MB\n",
            "Optimizer stripped from runs/detect/train4/weights/best.pt, 5.5MB\n",
            "\n",
            "Validating runs/detect/train4/weights/best.pt...\n",
            "Ultralytics 8.3.189 ğŸš€ Python-3.12.11 torch-2.8.0+cu126 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "YOLO11n summary (fused): 100 layers, 2,583,517 parameters, 0 gradients, 6.3 GFLOPs\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 174/174 7.0it/s 25.0s\n",
            "                   all       5550       5550      0.994      0.989      0.994      0.897\n",
            "                 happy       1737       1737      0.997      0.993      0.995      0.903\n",
            "                   sad       1274       1274      0.998      0.996      0.995      0.912\n",
            "                 angry       1104       1104      0.995      0.994      0.995       0.91\n",
            "             surprised        836        836      0.995      0.988      0.995      0.887\n",
            "               fearful        277        277      0.986      0.986      0.995      0.881\n",
            "             disgusted        177        177      0.989      0.983      0.991      0.883\n",
            "               neutral        145        145          1      0.984      0.994      0.904\n",
            "Speed: 0.2ms preprocess, 1.0ms inference, 0.0ms loss, 1.0ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train4\u001b[0m\n",
            "Model saved to: models/yolo11_rgb_only_20250831_053844.pt\n",
            "âš ï¸ Simulating training history for visualization\n",
            "ğŸ“Š Training history saved: outputs/multimodal_emotion_detection/visualizations/training_history_rgb_only.png\n",
            "ğŸ“Š Training summary table saved: outputs/multimodal_emotion_detection/visualizations/training_summary_rgb_only.png\n",
            "ğŸ“Š Loss history saved: outputs/multimodal_emotion_detection/visualizations/loss_history_rgb_only.png\n",
            "ğŸ“Š Accuracy history saved: outputs/multimodal_emotion_detection/visualizations/accuracy_history_rgb_only.png\n",
            "\n",
            "============================================================\n",
            "YOLO11 TRAINING COMPLETED\n",
            "============================================================\n",
            "Training time: 95.3 minutes\n",
            "Model saved to: models/yolo11_rgb_only_20250831_053844.pt\n",
            "Results saved to: outputs/multimodal_emotion_detection/training_results_rgb_only.json\n",
            "Visualizations saved to: outputs/multimodal_emotion_detection/visualizations\n",
            "\n",
            "âœ… Training completed successfully!\n",
            "ğŸ“Š Training time: 95.3 minutes\n",
            "ğŸ’¾ Model saved to: models/yolo11_rgb_only_20250831_053844.pt\n"
          ]
        }
      ],
      "source": [
        "!python main_yolo11.py --train --modality rgb_only --epochs 30 --batch-size 16 --data yolo_emotion_dataset/data.yaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJoPqQtut8qb",
        "outputId": "feb2b741-5d7a-466b-ab15-eb9ab6330538"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file âœ… \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1756871743.059697    2513 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1756871743.066151    2513 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1756871743.082605    2513 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1756871743.082648    2513 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1756871743.082651    2513 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1756871743.082654    2513 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "============================================================\n",
            "YOLO11 EMOTION DETECTION EVALUATION\n",
            "============================================================\n",
            "YOLO11 Evaluator initialized for rgb_only\n",
            "Device: cuda\n",
            "Output directory: outputs/yolo11_evaluation\n",
            "======================================================================\n",
            "YOLO11 EMOTION DETECTION EVALUATION\n",
            "======================================================================\n",
            "Model: models/yolo11_rgb_only_20250831_053844.pt\n",
            "Test dataset: yolo_emotion_dataset/test\n",
            "Confidence threshold: 0.25\n",
            "IoU threshold: 0.5\n",
            "\n",
            "ğŸ“¥ Loading YOLO11 model from: models/yolo11_rgb_only_20250831_053844.pt\n",
            "âœ… Model loaded successfully\n",
            "   Model type: <class 'ultralytics.models.yolo.model.YOLO'>\n",
            "\n",
            "ğŸ“‚ Loading test dataset from: yolo_emotion_dataset/test\n",
            "âœ… Loaded 6395 test images\n",
            "âœ… Loaded 6395 ground truth labels\n",
            "\n",
            "ğŸ“Š Test set class distribution:\n",
            "   angry: 1333\n",
            "   disgusted: 221\n",
            "   fearful: 346\n",
            "   happy: 1995\n",
            "   neutral: 181\n",
            "   sad: 1314\n",
            "   surprised: 1005\n",
            "\n",
            "ğŸ” Running inference on 6395 images...\n",
            "   Processed 100/6395 images\n",
            "   Processed 200/6395 images\n",
            "   Processed 300/6395 images\n",
            "   Processed 400/6395 images\n",
            "   Processed 500/6395 images\n",
            "   Processed 600/6395 images\n",
            "   Processed 700/6395 images\n",
            "   Processed 800/6395 images\n",
            "   Processed 900/6395 images\n",
            "   Processed 1000/6395 images\n",
            "   Processed 1100/6395 images\n",
            "   Processed 1200/6395 images\n",
            "   Processed 1300/6395 images\n",
            "   Processed 1400/6395 images\n",
            "   Processed 1500/6395 images\n",
            "   Processed 1600/6395 images\n",
            "   Processed 1700/6395 images\n",
            "   Processed 1800/6395 images\n",
            "   Processed 1900/6395 images\n",
            "   Processed 2000/6395 images\n",
            "   Processed 2100/6395 images\n",
            "   Processed 2200/6395 images\n",
            "   Processed 2300/6395 images\n",
            "   Processed 2400/6395 images\n",
            "   Processed 2500/6395 images\n",
            "   Processed 2600/6395 images\n",
            "   Processed 2700/6395 images\n",
            "   Processed 2800/6395 images\n",
            "   Processed 2900/6395 images\n",
            "   Processed 3000/6395 images\n",
            "   Processed 3100/6395 images\n",
            "   Processed 3200/6395 images\n",
            "   Processed 3300/6395 images\n",
            "   Processed 3400/6395 images\n",
            "   Processed 3500/6395 images\n",
            "   Processed 3600/6395 images\n",
            "   Processed 3700/6395 images\n",
            "   Processed 3800/6395 images\n",
            "   Processed 3900/6395 images\n",
            "   Processed 4000/6395 images\n",
            "   Processed 4100/6395 images\n",
            "   Processed 4200/6395 images\n",
            "   Processed 4300/6395 images\n",
            "   Processed 4400/6395 images\n",
            "   Processed 4500/6395 images\n",
            "   Processed 4600/6395 images\n",
            "   Processed 4700/6395 images\n",
            "   Processed 4800/6395 images\n",
            "   Processed 4900/6395 images\n",
            "   Processed 5000/6395 images\n",
            "   Processed 5100/6395 images\n",
            "   Processed 5200/6395 images\n",
            "   Processed 5300/6395 images\n",
            "   Processed 5400/6395 images\n",
            "   Processed 5500/6395 images\n",
            "   Processed 5600/6395 images\n",
            "   Processed 5700/6395 images\n",
            "   Processed 5800/6395 images\n",
            "   Processed 5900/6395 images\n",
            "   Processed 6000/6395 images\n",
            "   Processed 6100/6395 images\n",
            "   Processed 6200/6395 images\n",
            "   Processed 6300/6395 images\n",
            "âœ… Inference completed\n",
            "   Average inference time: 14.57ms per image\n",
            "\n",
            "ğŸ“Š Calculating evaluation metrics...\n",
            "âœ… Metrics calculated\n",
            "\n",
            "ğŸ¨ Generating evaluation visualizations...\n",
            "   ğŸ“Š Confusion matrix saved: outputs/yolo11_evaluation/visualizations/confusion_matrix_yolo11.png\n",
            "   ğŸ“Š Per-class metrics saved: outputs/yolo11_evaluation/visualizations/per_class_metrics_yolo11.png\n",
            "   ğŸ“Š Classification report saved: outputs/yolo11_evaluation/visualizations/classification_report_yolo11.png\n",
            "âœ… Visualizations saved to: outputs/yolo11_evaluation/visualizations\n",
            "ğŸ“ Evaluation results saved: outputs/yolo11_evaluation/results/yolo11_evaluation_20250903_053515.json\n",
            "\n",
            "======================================================================\n",
            "YOLO11 EMOTION DETECTION - EVALUATION SUMMARY\n",
            "======================================================================\n",
            "ğŸ¤– Model: yolo11_rgb_only_20250831_053844.pt\n",
            "ğŸ“Š Modality: rgb_only\n",
            "ğŸ¯ Confidence threshold: 0.25\n",
            "\n",
            "ğŸ“‚ Dataset:\n",
            "   Total images: 6395\n",
            "   Total faces: 6395\n",
            "\n",
            "ğŸ¯ Classification Performance:\n",
            "   Accuracy:  0.993\n",
            "   Precision: 0.993\n",
            "   Recall:    0.993\n",
            "   F1-Score:  0.993\n",
            "\n",
            "ğŸ” Detection Performance:\n",
            "   Precision: 0.993\n",
            "   Recall:    0.993\n",
            "   F1-Score:  0.993\n",
            "   True Positives:  6349\n",
            "   False Positives: 46\n",
            "   False Negatives: 46\n",
            "\n",
            "â±ï¸ Inference Timing:\n",
            "   Mean time:   14.57ms\n",
            "   Median time: 13.83ms\n",
            "   95th percentile: 16.33ms\n",
            "   FPS: 68.6\n",
            "\n",
            "ğŸ“ Visualizations: outputs/yolo11_evaluation/visualizations\n",
            "ğŸ“ Results: outputs/yolo11_evaluation/results\n",
            "======================================================================\n",
            "\n",
            "âœ… Evaluation completed successfully!\n",
            "ğŸ“Š Results saved to: outputs/yolo11_evaluation/\n"
          ]
        }
      ],
      "source": [
        "!python main_yolo11.py --evaluate --model models/yolo11_rgb_only_20250831_053844.pt --test-data yolo_emotion_dataset/test --conf 0.25"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OeOL8Fe85Hw3"
      },
      "outputs": [],
      "source": [
        "# Thermal Modality --"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KbJG1i3eFrTJ",
        "outputId": "f78236aa-c57b-44c7-c93d-18d96782ee13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1756661075.137051   21840 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1756661075.143689   21840 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1756661075.160526   21840 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1756661075.160553   21840 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1756661075.160557   21840 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1756661075.160559   21840 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "============================================================\n",
            "CONVERTING EMOTION DATASET TO YOLO FORMAT\n",
            "============================================================\n",
            "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "W0000 00:00:1756661078.551934   21900 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
            "Converting 4133 images from Thermal...\n",
            "  Progress: 1000/4133 files processed...\n",
            "  Progress: 2000/4133 files processed...\n",
            "  Progress: 3000/4133 files processed...\n",
            "  Progress: 4000/4133 files processed...\n",
            "âœ… Converted 4133 files, skipped 0 files from Thermal\n",
            "âœ… Processed thermal folder: Thermal\n",
            "Converting 16542 images from ThermalAug...\n",
            "  Progress: 1000/16542 files processed...\n",
            "  Progress: 2000/16542 files processed...\n",
            "  Progress: 3000/16542 files processed...\n",
            "  Progress: 4000/16542 files processed...\n",
            "  Progress: 5000/16542 files processed...\n",
            "  Progress: 6000/16542 files processed...\n",
            "  Progress: 7000/16542 files processed...\n",
            "  Progress: 8000/16542 files processed...\n",
            "  Progress: 9000/16542 files processed...\n",
            "  Progress: 10000/16542 files processed...\n",
            "  Progress: 11000/16542 files processed...\n",
            "  Progress: 12000/16542 files processed...\n",
            "  Progress: 13000/16542 files processed...\n",
            "  Progress: 14000/16542 files processed...\n",
            "  Progress: 15000/16542 files processed...\n",
            "  Progress: 16000/16542 files processed...\n",
            "âœ… Converted 16542 files, skipped 0 files from ThermalAug\n",
            "âœ… Processed thermal folder: ThermalAug\n",
            "Total converted files: 20675\n",
            "Dataset split: 13232 train, 3308 val, 4135 test\n",
            "Created YOLO data configuration: yolo_thermal_dataset/data.yaml\n",
            "\n",
            "âœ… Dataset conversion completed!\n",
            "ğŸ“ Output directory: yolo_thermal_dataset\n",
            "ğŸ“„ Data configuration: yolo_thermal_dataset/data.yaml\n",
            "ğŸ“Š Total converted files: 20675\n",
            "ğŸ“‚ Data splits: Train=13232, Val=3308, Test=4135\n",
            "\n",
            "ğŸ¯ Class distribution in converted dataset:\n",
            "   angry: 3895\n",
            "   disgusted: 1103\n",
            "   fearful: 1730\n",
            "   happy: 6028\n",
            "   neutral: 515\n",
            "   sad: 4412\n",
            "   surprised: 2992\n",
            "ğŸ“ˆ Total unique emotions: 7\n",
            "\n",
            "âœ… Dataset conversion completed!\n",
            "ğŸ“ Output directory: yolo_thermal_dataset\n",
            "ğŸ“„ Data config: yolo_thermal_dataset/data.yaml\n",
            "\n",
            "ğŸš€ To train YOLO11:\n",
            "python main_yolo11.py --train --modality thermal_only --data yolo_thermal_dataset/data.yaml\n"
          ]
        }
      ],
      "source": [
        "# 3. Convert dataset thermal Only\n",
        "!python main_yolo11.py --convert --modality thermal_only  --output-dir yolo_thermal_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qH8qtGyFrXH",
        "outputId": "e10cfb01-418a-4d88-b93f-be6877f51371"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1756662034.901688   25926 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1756662034.908118   25926 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1756662034.924695   25926 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1756662034.924721   25926 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1756662034.924724   25926 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1756662034.924727   25926 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "============================================================\n",
            "TRAINING YOLO11 FOR EMOTION DETECTION (THERMAL_ONLY)\n",
            "============================================================\n",
            "Initialized Thermal-only YOLO11 model (n)\n",
            "YOLO11 Trainer initialized for thermal_only\n",
            "Device: cuda\n",
            "\n",
            "Starting YOLO11 training for thermal_only\n",
            "============================================================\n",
            "Training parameters:\n",
            "  Data config: yolo_thermal_dataset/data.yaml\n",
            "  Epochs: 30\n",
            "  Batch size: 16\n",
            "  Image size: 640\n",
            "  Device: cuda\n",
            "Ultralytics 8.3.190 ğŸš€ Python-3.12.11 torch-2.8.0+cu126 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=yolo_thermal_dataset/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=30, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo11n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train5, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs/detect/train5, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% â”â”â”â”â”â”â”â”â”â”â”â” 755.1/755.1KB 22.2MB/s 0.0s\n",
            "Overriding model.yaml nc=80 with nc=7\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
            "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
            "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
            " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
            " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
            " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
            " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
            " 23        [16, 19, 22]  1    432037  ultralytics.nn.modules.head.Detect           [7, [64, 128, 256]]           \n",
            "YOLO11n summary: 181 layers, 2,591,205 parameters, 2,591,189 gradients, 6.4 GFLOPs\n",
            "\n",
            "Transferred 448/499 items from pretrained weights\n",
            "Freezing layer 'model.23.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.5Â±0.0 ms, read: 9.0Â±2.9 MB/s, size: 12.0 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/test/yolo_thermal_dataset/train/labels... 13232 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 13232/13232 74.8it/s 2:57\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/drive/MyDrive/test/yolo_thermal_dataset/train/labels.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.6Â±0.1 ms, read: 5.4Â±6.9 MB/s, size: 41.3 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/test/yolo_thermal_dataset/val/labels... 3308 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 3308/3308 234.4it/s 14.1s\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/drive/MyDrive/test/yolo_thermal_dataset/val/labels.cache\n",
            "Plotting labels to runs/detect/train5/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000909, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train5\u001b[0m\n",
            "Starting training for 30 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       1/30      2.38G      1.251      2.776      1.476         32        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 827/827 7.4it/s 1:51\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 104/104 4.9it/s 21.3s\n",
            "                   all       3308       3308      0.353      0.467      0.283      0.175\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       2/30      2.61G      1.168      1.898      1.335         33        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 827/827 8.8it/s 1:34\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 104/104 7.8it/s 13.3s\n",
            "                   all       3308       3308      0.431      0.515      0.371      0.245\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       3/30      2.63G      1.147      1.677      1.309         35        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 827/827 9.0it/s 1:31\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 104/104 7.8it/s 13.4s\n",
            "                   all       3308       3308      0.395      0.578      0.464      0.319\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       4/30      2.64G      1.115      1.555      1.286         34        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 827/827 9.1it/s 1:31\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 104/104 7.8it/s 13.4s\n",
            "                   all       3308       3308       0.55      0.561      0.532      0.379\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       5/30      2.66G      1.067      1.458      1.258         39        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 827/827 9.1it/s 1:30\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 104/104 7.8it/s 13.4s\n",
            "                   all       3308       3308      0.579      0.637      0.628      0.448\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       6/30      2.67G      1.038      1.382      1.236         27        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 827/827 9.1it/s 1:31\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 104/104 7.9it/s 13.2s\n",
            "                   all       3308       3308      0.615      0.595       0.67      0.479\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       7/30      2.69G      1.014      1.326      1.221         34        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 827/827 9.0it/s 1:31\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 104/104 7.8it/s 13.3s\n",
            "                   all       3308       3308      0.598      0.669      0.694      0.509\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       8/30       2.7G     0.9891      1.257      1.207         32        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 827/827 9.1it/s 1:31\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 104/104 7.8it/s 13.3s\n",
            "                   all       3308       3308      0.653      0.672      0.693      0.504\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       9/30      2.72G     0.9883      1.236      1.209         26        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 827/827 9.1it/s 1:31\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 104/104 7.7it/s 13.5s\n",
            "                   all       3308       3308      0.702       0.68       0.75      0.554\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      10/30      2.73G     0.9616      1.184      1.192         31        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 827/827 9.0it/s 1:32\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 104/104 7.7it/s 13.5s\n",
            "                   all       3308       3308      0.734      0.694      0.784      0.578\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      11/30      2.75G      0.954      1.157      1.183         26        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 827/827 9.1it/s 1:31\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 104/104 7.9it/s 13.2s\n",
            "                   all       3308       3308      0.803      0.687      0.795       0.59\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      12/30      2.76G     0.9414      1.115      1.179         36        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 827/827 9.1it/s 1:31\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 104/104 7.8it/s 13.3s\n",
            "                   all       3308       3308      0.789      0.724      0.816       0.61\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      13/30      2.78G     0.9329      1.083      1.171         38        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 827/827 9.1it/s 1:31\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 104/104 7.7it/s 13.6s\n",
            "                   all       3308       3308      0.795      0.751      0.837      0.629\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      14/30      2.79G     0.9267       1.06      1.167         35        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 827/827 9.1it/s 1:31\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 104/104 7.8it/s 13.3s\n",
            "                   all       3308       3308      0.828      0.728      0.842      0.634\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      15/30      2.81G     0.9114      1.034      1.161         35        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 827/827 9.0it/s 1:32\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 104/104 7.8it/s 13.4s\n",
            "                   all       3308       3308      0.788      0.788      0.859       0.64\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      16/30      2.82G     0.9064      1.014      1.154         32        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 827/827 9.0it/s 1:31\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 104/104 7.6it/s 13.6s\n",
            "                   all       3308       3308      0.828      0.772      0.854      0.649\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      17/30      2.84G     0.8912     0.9796       1.15         27        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 827/827 9.1it/s 1:31\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 104/104 7.8it/s 13.3s\n",
            "                   all       3308       3308      0.852      0.807      0.876      0.662\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      18/30      2.85G     0.8789     0.9628      1.142         30        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 827/827 9.1it/s 1:31\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 104/104 7.8it/s 13.4s\n",
            "                   all       3308       3308      0.843      0.797       0.88      0.673\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      19/30      2.87G     0.8722     0.9417      1.136         23        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 827/827 9.1it/s 1:31\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 104/104 7.8it/s 13.3s\n",
            "                   all       3308       3308       0.86      0.795      0.887      0.681\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      20/30      2.88G     0.8658     0.9185      1.134         34        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 827/827 9.1it/s 1:31\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 104/104 7.8it/s 13.3s\n",
            "                   all       3308       3308      0.833      0.836      0.899      0.689\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      21/30       2.9G     0.8778     0.6749      1.209         16        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 827/827 9.1it/s 1:31\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 104/104 7.8it/s 13.3s\n",
            "                   all       3308       3308      0.855      0.838      0.906      0.697\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      22/30      2.91G     0.8499     0.6372       1.19         16        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 827/827 9.2it/s 1:30\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 104/104 7.9it/s 13.2s\n",
            "                   all       3308       3308       0.87      0.846      0.917      0.712\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      23/30      2.93G     0.8315     0.6106      1.174         16        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 827/827 9.2it/s 1:30\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 104/104 7.9it/s 13.1s\n",
            "                   all       3308       3308      0.856      0.852      0.914      0.712\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      24/30      2.94G     0.8277     0.5802      1.172         16        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 827/827 9.2it/s 1:30\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 104/104 7.8it/s 13.4s\n",
            "                   all       3308       3308      0.872      0.855      0.924      0.722\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      25/30      2.96G     0.8135      0.568       1.16         16        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 827/827 8.7it/s 1:35\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 104/104 7.6it/s 13.6s\n",
            "                   all       3308       3308      0.875      0.877      0.935      0.729\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      26/30      2.97G     0.8029     0.5388      1.151         16        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 827/827 9.1it/s 1:31\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 104/104 7.7it/s 13.4s\n",
            "                   all       3308       3308      0.862      0.885      0.931       0.73\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      27/30      2.99G     0.7907     0.5221      1.145         16        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 827/827 9.1it/s 1:31\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 104/104 7.8it/s 13.4s\n",
            "                   all       3308       3308      0.879      0.881      0.939      0.736\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      28/30         3G     0.7755     0.5051      1.134         16        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 827/827 9.1it/s 1:31\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 104/104 7.7it/s 13.5s\n",
            "                   all       3308       3308      0.882      0.882      0.938       0.74\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      29/30      3.02G     0.7678     0.4942      1.126         16        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 827/827 9.1it/s 1:31\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 104/104 7.8it/s 13.4s\n",
            "                   all       3308       3308      0.884      0.887      0.938      0.741\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      30/30      3.03G     0.7577     0.4746      1.121         16        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 827/827 9.1it/s 1:31\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 104/104 7.7it/s 13.5s\n",
            "                   all       3308       3308      0.878       0.89       0.94      0.745\n",
            "\n",
            "30 epochs completed in 0.882 hours.\n",
            "Optimizer stripped from runs/detect/train5/weights/last.pt, 5.5MB\n",
            "Optimizer stripped from runs/detect/train5/weights/best.pt, 5.5MB\n",
            "\n",
            "Validating runs/detect/train5/weights/best.pt...\n",
            "Ultralytics 8.3.190 ğŸš€ Python-3.12.11 torch-2.8.0+cu126 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "YOLO11n summary (fused): 100 layers, 2,583,517 parameters, 0 gradients, 6.3 GFLOPs\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 104/104 6.9it/s 15.0s\n",
            "                   all       3308       3308      0.879       0.89       0.94      0.745\n",
            "                 happy        964        964      0.905      0.876      0.949      0.741\n",
            "                   sad        706        706      0.925      0.938      0.977      0.772\n",
            "                 angry        623        623      0.884      0.851      0.931      0.719\n",
            "             surprised        479        479      0.808       0.81      0.886      0.668\n",
            "               fearful        277        277      0.928      0.931      0.975      0.793\n",
            "             disgusted        177        177      0.943      0.943      0.963      0.788\n",
            "               neutral         82         82      0.757      0.878        0.9      0.734\n",
            "Speed: 0.2ms preprocess, 1.0ms inference, 0.0ms loss, 0.9ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train5\u001b[0m\n",
            "Model saved to: models/yolo11_thermal_only_20250831_183804.pt\n",
            "âš ï¸ Simulating training history for visualization\n",
            "ğŸ“Š Training history saved: outputs/multimodal_emotion_detection/visualizations/training_history_thermal_only.png\n",
            "ğŸ“Š Training summary table saved: outputs/multimodal_emotion_detection/visualizations/training_summary_thermal_only.png\n",
            "ğŸ“Š Loss history saved: outputs/multimodal_emotion_detection/visualizations/loss_history_thermal_only.png\n",
            "ğŸ“Š Accuracy history saved: outputs/multimodal_emotion_detection/visualizations/accuracy_history_thermal_only.png\n",
            "\n",
            "============================================================\n",
            "YOLO11 TRAINING COMPLETED\n",
            "============================================================\n",
            "Training time: 57.4 minutes\n",
            "Model saved to: models/yolo11_thermal_only_20250831_183804.pt\n",
            "Results saved to: outputs/multimodal_emotion_detection/training_results_thermal_only.json\n",
            "Visualizations saved to: outputs/multimodal_emotion_detection/visualizations\n",
            "\n",
            "âœ… Training completed successfully!\n",
            "ğŸ“Š Training time: 57.4 minutes\n",
            "ğŸ’¾ Model saved to: models/yolo11_thermal_only_20250831_183804.pt\n"
          ]
        }
      ],
      "source": [
        "!python main_yolo11.py --train --modality thermal_only --epochs 30 --batch-size 16 \\\n",
        "    --data yolo_thermal_dataset/data.yaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XK2HGXY-FrbL",
        "outputId": "49b0672d-85b9-42af-c710-0f0de56672f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1756877904.512776   28549 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1756877904.519318   28549 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1756877904.535732   28549 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1756877904.535763   28549 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1756877904.535766   28549 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1756877904.535768   28549 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "============================================================\n",
            "YOLO11 EMOTION DETECTION EVALUATION\n",
            "============================================================\n",
            "YOLO11 Evaluator initialized for thermal_only\n",
            "Device: cuda\n",
            "Output directory: outputs/yolo11_evaluation\n",
            "======================================================================\n",
            "YOLO11 EMOTION DETECTION EVALUATION\n",
            "======================================================================\n",
            "Model: models/yolo11_thermal_only_20250831_183804.pt\n",
            "Test dataset: yolo_thermal_dataset/test\n",
            "Confidence threshold: 0.25\n",
            "IoU threshold: 0.45\n",
            "\n",
            "ğŸ“¥ Loading YOLO11 model from: models/yolo11_thermal_only_20250831_183804.pt\n",
            "âœ… Model loaded successfully\n",
            "   Model type: <class 'ultralytics.models.yolo.model.YOLO'>\n",
            "\n",
            "ğŸ“‚ Loading test dataset from: yolo_thermal_dataset/test\n",
            "âœ… Loaded 4135 test images\n",
            "âœ… Loaded 4135 ground truth labels\n",
            "\n",
            "ğŸ“Š Test set class distribution:\n",
            "   angry: 779\n",
            "   disgusted: 221\n",
            "   fearful: 346\n",
            "   happy: 1206\n",
            "   neutral: 103\n",
            "   sad: 882\n",
            "   surprised: 598\n",
            "\n",
            "ğŸ” Running inference on 4135 images...\n",
            "   Processed 100/4135 images\n",
            "   Processed 200/4135 images\n",
            "   Processed 300/4135 images\n",
            "   Processed 400/4135 images\n",
            "   Processed 500/4135 images\n",
            "   Processed 600/4135 images\n",
            "   Processed 700/4135 images\n",
            "   Processed 800/4135 images\n",
            "   Processed 900/4135 images\n",
            "   Processed 1000/4135 images\n",
            "   Processed 1100/4135 images\n",
            "   Processed 1200/4135 images\n",
            "   Processed 1300/4135 images\n",
            "   Processed 1400/4135 images\n",
            "   Processed 1500/4135 images\n",
            "   Processed 1600/4135 images\n",
            "   Processed 1700/4135 images\n",
            "   Processed 1800/4135 images\n",
            "   Processed 1900/4135 images\n",
            "   Processed 2000/4135 images\n",
            "   Processed 2100/4135 images\n",
            "   Processed 2200/4135 images\n",
            "   Processed 2300/4135 images\n",
            "   Processed 2400/4135 images\n",
            "   Processed 2500/4135 images\n",
            "   Processed 2600/4135 images\n",
            "   Processed 2700/4135 images\n",
            "   Processed 2800/4135 images\n",
            "   Processed 2900/4135 images\n",
            "   Processed 3000/4135 images\n",
            "   Processed 3100/4135 images\n",
            "   Processed 3200/4135 images\n",
            "   Processed 3300/4135 images\n",
            "   Processed 3400/4135 images\n",
            "   Processed 3500/4135 images\n",
            "   Processed 3600/4135 images\n",
            "   Processed 3700/4135 images\n",
            "   Processed 3800/4135 images\n",
            "   Processed 3900/4135 images\n",
            "   Processed 4000/4135 images\n",
            "   Processed 4100/4135 images\n",
            "âœ… Inference completed\n",
            "   Average inference time: 14.20ms per image\n",
            "\n",
            "ğŸ“Š Calculating evaluation metrics...\n",
            "âœ… Metrics calculated\n",
            "\n",
            "ğŸ¨ Generating evaluation visualizations...\n",
            "   ğŸ“Š Confusion matrix saved: outputs/yolo11_evaluation/visualizations/confusion_matrix_yolo11.png\n",
            "   ğŸ“Š Per-class metrics saved: outputs/yolo11_evaluation/visualizations/per_class_metrics_yolo11.png\n",
            "   ğŸ“Š Classification report saved: outputs/yolo11_evaluation/visualizations/classification_report_yolo11.png\n",
            "âœ… Visualizations saved to: outputs/yolo11_evaluation/visualizations\n",
            "ğŸ“ Evaluation results saved: outputs/yolo11_evaluation/results/yolo11_evaluation_20250903_063946.json\n",
            "\n",
            "======================================================================\n",
            "YOLO11 EMOTION DETECTION - EVALUATION SUMMARY\n",
            "======================================================================\n",
            "ğŸ¤– Model: yolo11_thermal_only_20250831_183804.pt\n",
            "ğŸ“Š Modality: thermal_only\n",
            "ğŸ¯ Confidence threshold: 0.25\n",
            "\n",
            "ğŸ“‚ Dataset:\n",
            "   Total images: 4135\n",
            "   Total faces: 4135\n",
            "\n",
            "ğŸ¯ Classification Performance:\n",
            "   Accuracy:  0.973\n",
            "   Precision: 0.973\n",
            "   Recall:    0.973\n",
            "   F1-Score:  0.973\n",
            "\n",
            "ğŸ” Detection Performance:\n",
            "   Precision: 0.973\n",
            "   Recall:    0.964\n",
            "   F1-Score:  0.968\n",
            "   True Positives:  3987\n",
            "   False Positives: 112\n",
            "   False Negatives: 148\n",
            "\n",
            "â±ï¸ Inference Timing:\n",
            "   Mean time:   14.20ms\n",
            "   Median time: 13.76ms\n",
            "   95th percentile: 16.28ms\n",
            "   FPS: 70.4\n",
            "\n",
            "ğŸ“ Visualizations: outputs/yolo11_evaluation/visualizations\n",
            "ğŸ“ Results: outputs/yolo11_evaluation/results\n",
            "======================================================================\n",
            "\n",
            "âœ… Evaluation completed successfully!\n",
            "ğŸ“Š Results saved to: outputs/yolo11_evaluation/\n"
          ]
        }
      ],
      "source": [
        "!python main_yolo11.py --evaluate --modality thermal_only \\\n",
        "    --model  models/yolo11_thermal_only_20250831_183804.pt \\\n",
        "    --test-data yolo_thermal_dataset/test \\\n",
        "    --conf 0.25 --iou 0.45"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J_hvkpQ6Frei"
      },
      "outputs": [],
      "source": [
        "# Early Fusion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oygacQQ3YkrX",
        "outputId": "78196660-a216-4eec-f3b2-f8c168322420"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1756694004.071901   61382 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1756694004.078550   61382 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1756694004.095515   61382 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1756694004.095549   61382 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1756694004.095552   61382 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1756694004.095555   61382 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "============================================================\n",
            "FUSING EXISTING RGB AND THERMAL DATASETS\n",
            "============================================================\n",
            "âœ… Found RGB dataset: yolo_emotion_dataset\n",
            "âœ… Found Thermal dataset: yolo_thermal_dataset\n",
            "ğŸ”„ Fusing datasets for early_fusion...\n",
            "ğŸ“ RGB dataset: yolo_emotion_dataset\n",
            "ğŸ“ Thermal dataset: yolo_thermal_dataset\n",
            "ğŸ“ Output: yolo_early_fusion_dataset\n",
            "\n",
            "ğŸ“‚ Processing train split...\n",
            "   RGB images: 16843\n",
            "   Thermal images: 13232\n",
            "âš ï¸  Warning: Mismatch in train - RGB: 16843, Thermal: 13232\n",
            "   âœ… Processed 13232 fused pairs\n",
            "\n",
            "ğŸ“‚ Processing val split...\n",
            "   RGB images: 5550\n",
            "   Thermal images: 3308\n",
            "âš ï¸  Warning: Mismatch in val - RGB: 5550, Thermal: 3308\n",
            "   âœ… Processed 3308 fused pairs\n",
            "\n",
            "ğŸ“‚ Processing test split...\n",
            "   RGB images: 6395\n",
            "   Thermal images: 4135\n",
            "âš ï¸  Warning: Mismatch in test - RGB: 6395, Thermal: 4135\n",
            "   âœ… Processed 4135 fused pairs\n",
            "\n",
            "âœ… Dataset fusion completed!\n",
            "ğŸ“ Output directory: yolo_early_fusion_dataset\n",
            "ğŸ“„ Data configuration: yolo_early_fusion_dataset/data.yaml\n",
            "ğŸ“Š Total fused files: 20675\n",
            "ğŸ¯ Fusion type: early_fusion\n",
            "\n",
            "âœ… Dataset fusion completed!\n",
            "ğŸ“ Output directory: yolo_early_fusion_dataset\n",
            "ğŸ“„ Data config: yolo_early_fusion_dataset/data.yaml\n",
            "\n",
            "ğŸš€ To train YOLO11:\n",
            "python main_yolo11.py --train --modality early_fusion --data yolo_early_fusion_dataset/data.yaml\n"
          ]
        }
      ],
      "source": [
        "!python main_yolo11.py --fuse --modality early_fusion --output-dir yolo_early_fusion_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ADL1LvEfJCJ"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kufU_PBeYlC7",
        "outputId": "25d49519-fba4-48cd-ad5d-0f5ea42df60d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1756701130.018713   96087 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1756701130.025414   96087 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1756701130.043168   96087 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1756701130.043199   96087 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1756701130.043202   96087 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1756701130.043205   96087 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "============================================================\n",
            "TRAINING YOLO11 FOR EMOTION DETECTION (EARLY_FUSION)\n",
            "============================================================\n",
            "âš ï¸ Early fusion is simulated by channel-wise concatenation of RGB and Thermal images\n",
            "   In production, you would modify the YOLO11 backbone to accept 6-channel input\n",
            "Initialized Early Fusion YOLO11 model (n)\n",
            "YOLO11 Trainer initialized for early_fusion\n",
            "Device: cuda\n",
            "\n",
            "Starting YOLO11 training for early_fusion\n",
            "============================================================\n",
            "Training parameters:\n",
            "  Data config: yolo_early_fusion_dataset/data.yaml\n",
            "  Epochs: 30\n",
            "  Batch size: 16\n",
            "  Image size: 640\n",
            "  Device: cuda\n",
            "Ultralytics 8.3.190 ğŸš€ Python-3.12.11 torch-2.8.0+cu126 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=yolo_early_fusion_dataset/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=30, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo11n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train7, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs/detect/train7, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=7\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
            "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
            "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
            " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
            " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
            " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
            " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
            " 23        [16, 19, 22]  1    432037  ultralytics.nn.modules.head.Detect           [7, [64, 128, 256]]           \n",
            "YOLO11n summary: 181 layers, 2,591,205 parameters, 2,591,189 gradients, 6.4 GFLOPs\n",
            "\n",
            "Transferred 448/499 items from pretrained weights\n",
            "Freezing layer 'model.23.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.5Â±0.1 ms, read: 21.5Â±32.5 MB/s, size: 40.0 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/test/yolo_early_fusion_dataset/train/labels.cache... 26464 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 26464/26464 289812169.9it/s 0.0s\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.6Â±0.2 ms, read: 2.3Â±1.9 MB/s, size: 12.1 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/test/yolo_early_fusion_dataset/val/labels.cache... 6616 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 6616/6616 50179955.3it/s 0.0s\n",
            "Plotting labels to runs/detect/train7/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train7\u001b[0m\n",
            "Starting training for 30 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       1/30      2.56G     0.9816      2.616      1.194         25        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1654/1654 7.4it/s 3:45\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 207/207 5.7it/s 36.6s\n",
            "                   all       6616       6616      0.393      0.539      0.466      0.373\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       2/30      2.79G     0.8452      1.552      1.061         32        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1654/1654 8.9it/s 3:06\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 207/207 7.7it/s 27.0s\n",
            "                   all       6616       6616      0.585      0.656      0.665      0.538\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       3/30      2.79G     0.8558      1.211      1.071         22        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1654/1654 9.1it/s 3:02\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 207/207 7.8it/s 26.5s\n",
            "                   all       6616       6616      0.578      0.656      0.646      0.513\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       4/30      2.79G     0.8438      1.093      1.076         18        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1654/1654 9.1it/s 3:01\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 207/207 7.9it/s 26.4s\n",
            "                   all       6616       6616      0.696        0.7      0.761      0.622\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       5/30      2.79G     0.7955     0.9574      1.053         28        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1654/1654 9.2it/s 3:00\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 207/207 7.8it/s 26.5s\n",
            "                   all       6616       6616      0.754      0.737      0.818      0.686\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       6/30      2.79G     0.7595     0.8669      1.035         30        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1654/1654 9.1it/s 3:01\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 207/207 7.9it/s 26.1s\n",
            "                   all       6616       6616        0.8      0.743      0.852      0.717\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       7/30      2.79G     0.7395     0.8047      1.027         25        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1654/1654 9.1it/s 3:02\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 207/207 7.9it/s 26.3s\n",
            "                   all       6616       6616      0.831      0.796      0.886      0.751\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       8/30      2.79G     0.7191     0.7594      1.014         23        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1654/1654 9.2it/s 3:00\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 207/207 7.9it/s 26.1s\n",
            "                   all       6616       6616      0.844      0.829      0.912      0.785\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       9/30      2.79G     0.7077     0.7155       1.01         23        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1654/1654 9.1it/s 3:02\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 207/207 7.9it/s 26.1s\n",
            "                   all       6616       6616      0.912      0.878      0.952       0.82\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      10/30      2.79G     0.6953     0.6817      1.003         29        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1654/1654 9.2it/s 3:01\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 207/207 7.9it/s 26.3s\n",
            "                   all       6616       6616      0.935      0.847      0.948      0.822\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      11/30       2.8G     0.6839      0.651     0.9982         29        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1654/1654 9.1it/s 3:01\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 207/207 7.9it/s 26.3s\n",
            "                   all       6616       6616      0.897      0.898      0.961      0.834\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      12/30       2.8G     0.6728      0.623      0.993         22        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1654/1654 9.1it/s 3:01\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 207/207 7.9it/s 26.2s\n",
            "                   all       6616       6616       0.95       0.87      0.965      0.841\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      13/30       2.8G     0.6687     0.6097     0.9899         26        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1654/1654 9.2it/s 3:01\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 207/207 8.0it/s 26.0s\n",
            "                   all       6616       6616      0.948      0.927      0.977      0.855\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      14/30       2.8G     0.6567     0.5785     0.9843         27        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1654/1654 9.1it/s 3:01\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 207/207 7.9it/s 26.2s\n",
            "                   all       6616       6616       0.96      0.915       0.98      0.861\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      15/30       2.8G     0.6514     0.5685     0.9838         28        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1654/1654 9.1it/s 3:01\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 207/207 7.8it/s 26.6s\n",
            "                   all       6616       6616      0.955       0.94      0.984      0.863\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      16/30       2.8G     0.6437     0.5468     0.9761         28        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1654/1654 9.1it/s 3:01\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 207/207 8.0it/s 26.0s\n",
            "                   all       6616       6616      0.957      0.952      0.986      0.869\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      17/30       2.8G     0.6358     0.5326     0.9739         26        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1654/1654 9.1it/s 3:01\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 207/207 8.0it/s 26.0s\n",
            "                   all       6616       6616      0.966      0.943      0.986       0.87\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      18/30       2.8G     0.6305     0.5162      0.971         33        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1654/1654 9.2it/s 3:01\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 207/207 7.9it/s 26.1s\n",
            "                   all       6616       6616      0.968      0.962      0.989      0.877\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      19/30       2.8G     0.6236     0.4998     0.9706         29        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1654/1654 9.1it/s 3:01\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 207/207 8.0it/s 25.8s\n",
            "                   all       6616       6616      0.964      0.971      0.991      0.879\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      20/30       2.8G     0.6152     0.4839      0.965         31        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1654/1654 9.1it/s 3:01\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 207/207 7.9it/s 26.2s\n",
            "                   all       6616       6616      0.985      0.963      0.992      0.882\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      21/30       2.8G     0.5455     0.3181     0.9429         16        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1654/1654 9.2it/s 2:59\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 207/207 7.9it/s 26.1s\n",
            "                   all       6616       6616      0.985      0.974      0.992      0.884\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      22/30       2.8G     0.5369     0.3013      0.937         16        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1654/1654 9.3it/s 2:58\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 207/207 8.0it/s 26.0s\n",
            "                   all       6616       6616      0.977      0.985      0.994       0.89\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      23/30       2.8G     0.5273     0.2853     0.9319         16        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1654/1654 9.3it/s 2:58\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 207/207 8.0it/s 26.0s\n",
            "                   all       6616       6616      0.991      0.979      0.994      0.893\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      24/30       2.8G     0.5179     0.2703     0.9261         16        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1654/1654 9.3it/s 2:59\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 207/207 8.0it/s 26.0s\n",
            "                   all       6616       6616      0.987      0.983      0.994      0.896\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      25/30       2.8G     0.5104     0.2567     0.9202         16        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1654/1654 9.2it/s 2:59\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 207/207 8.0it/s 25.9s\n",
            "                   all       6616       6616      0.988      0.991      0.994      0.897\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      26/30       2.8G     0.5022     0.2447     0.9173         16        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1654/1654 9.3it/s 2:58\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 207/207 8.0it/s 25.9s\n",
            "                   all       6616       6616      0.992      0.993      0.994      0.899\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      27/30       2.8G     0.4934     0.2332     0.9124         16        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1654/1654 9.3it/s 2:59\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 207/207 8.0it/s 26.0s\n",
            "                   all       6616       6616      0.992      0.994      0.995      0.902\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      28/30       2.8G     0.4858     0.2235     0.9064         16        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1654/1654 9.3it/s 2:58\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 207/207 8.0it/s 25.9s\n",
            "                   all       6616       6616      0.994      0.993      0.995      0.902\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      29/30       2.8G     0.4763     0.2129     0.9032         16        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1654/1654 9.2it/s 2:59\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 207/207 8.0it/s 25.9s\n",
            "                   all       6616       6616      0.995      0.993      0.995      0.905\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      30/30       2.8G     0.4695     0.2028     0.8986         16        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1654/1654 9.2it/s 2:59\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 207/207 7.9it/s 26.3s\n",
            "                   all       6616       6616      0.995      0.994      0.995      0.905\n",
            "\n",
            "30 epochs completed in 1.740 hours.\n",
            "Optimizer stripped from runs/detect/train7/weights/last.pt, 5.5MB\n",
            "Optimizer stripped from runs/detect/train7/weights/best.pt, 5.5MB\n",
            "\n",
            "Validating runs/detect/train7/weights/best.pt...\n",
            "Ultralytics 8.3.190 ğŸš€ Python-3.12.11 torch-2.8.0+cu126 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "YOLO11n summary (fused): 100 layers, 2,583,517 parameters, 0 gradients, 6.3 GFLOPs\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 207/207 7.3it/s 28.5s\n",
            "                   all       6616       6616      0.995      0.994      0.995      0.905\n",
            "                 happy       2701       2701      0.994      0.997      0.995      0.906\n",
            "                   sad        706        706          1      0.999      0.995      0.909\n",
            "                 angry       1727       1727      0.995      0.998      0.995      0.915\n",
            "             surprised        479        479      0.994      0.971      0.994      0.877\n",
            "               fearful        554        554      0.999      0.993      0.995      0.894\n",
            "             disgusted        354        354      0.993          1      0.995      0.907\n",
            "               neutral         95         95       0.99          1      0.995      0.927\n",
            "Speed: 0.2ms preprocess, 1.1ms inference, 0.0ms loss, 0.8ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train7\u001b[0m\n",
            "Model saved to: models/yolo11_early_fusion_20250901_061809.pt\n",
            "âš ï¸ Simulating training history for visualization\n",
            "ğŸ“Š Training history saved: outputs/multimodal_emotion_detection/visualizations/training_history_early_fusion.png\n",
            "ğŸ“Š Training summary table saved: outputs/multimodal_emotion_detection/visualizations/training_summary_early_fusion.png\n",
            "ğŸ“Š Loss history saved: outputs/multimodal_emotion_detection/visualizations/loss_history_early_fusion.png\n",
            "ğŸ“Š Accuracy history saved: outputs/multimodal_emotion_detection/visualizations/accuracy_history_early_fusion.png\n",
            "\n",
            "============================================================\n",
            "YOLO11 TRAINING COMPLETED\n",
            "============================================================\n",
            "Training time: 105.9 minutes\n",
            "Model saved to: models/yolo11_early_fusion_20250901_061809.pt\n",
            "Results saved to: outputs/multimodal_emotion_detection/training_results_early_fusion.json\n",
            "Visualizations saved to: outputs/multimodal_emotion_detection/visualizations\n",
            "\n",
            "âœ… Training completed successfully!\n",
            "ğŸ“Š Training time: 105.9 minutes\n",
            "ğŸ’¾ Model saved to: models/yolo11_early_fusion_20250901_061809.pt\n"
          ]
        }
      ],
      "source": [
        "!python main_yolo11.py --train --modality early_fusion --epochs 30 --batch-size 16 --data yolo_early_fusion_dataset/data.yaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FROzFUimYlEg",
        "outputId": "e559319c-4409-4a0f-dd8a-1315cdd14dfd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1756707783.081363  123674 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1756707783.087941  123674 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1756707783.104676  123674 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1756707783.104715  123674 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1756707783.104718  123674 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1756707783.104721  123674 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "============================================================\n",
            "YOLO11 EMOTION DETECTION EVALUATION\n",
            "============================================================\n",
            "YOLO11 Evaluator initialized for rgb_only\n",
            "Device: cuda\n",
            "Output directory: outputs/yolo11_evaluation\n",
            "======================================================================\n",
            "YOLO11 EMOTION DETECTION EVALUATION\n",
            "======================================================================\n",
            "Model: models/yolo11_early_fusion_20250901_061809.pt\n",
            "Test dataset: yolo_early_fusion_dataset/test\n",
            "Confidence threshold: 0.25\n",
            "IoU threshold: 0.5\n",
            "\n",
            "ğŸ“¥ Loading YOLO11 model from: models/yolo11_early_fusion_20250901_061809.pt\n",
            "âœ… Model loaded successfully\n",
            "   Model type: <class 'ultralytics.models.yolo.model.YOLO'>\n",
            "\n",
            "ğŸ“‚ Loading test dataset from: yolo_early_fusion_dataset/test\n",
            "âœ… Loaded 8270 test images\n",
            "âœ… Loaded 8270 ground truth labels\n",
            "\n",
            "ğŸ“Š Test set class distribution:\n",
            "   angry: 2112\n",
            "   disgusted: 442\n",
            "   fearful: 692\n",
            "   happy: 3201\n",
            "   neutral: 284\n",
            "   sad: 941\n",
            "   surprised: 598\n",
            "\n",
            "ğŸ” Running inference on 8270 images...\n",
            "   Processed 100/8270 images\n",
            "   Processed 200/8270 images\n",
            "   Processed 300/8270 images\n",
            "   Processed 400/8270 images\n",
            "   Processed 500/8270 images\n",
            "   Processed 600/8270 images\n",
            "   Processed 700/8270 images\n",
            "   Processed 800/8270 images\n",
            "   Processed 900/8270 images\n",
            "   Processed 1000/8270 images\n",
            "   Processed 1100/8270 images\n",
            "   Processed 1200/8270 images\n",
            "   Processed 1300/8270 images\n",
            "   Processed 1400/8270 images\n",
            "   Processed 1500/8270 images\n",
            "   Processed 1600/8270 images\n",
            "   Processed 1700/8270 images\n",
            "   Processed 1800/8270 images\n",
            "   Processed 1900/8270 images\n",
            "   Processed 2000/8270 images\n",
            "   Processed 2100/8270 images\n",
            "   Processed 2200/8270 images\n",
            "   Processed 2300/8270 images\n",
            "   Processed 2400/8270 images\n",
            "   Processed 2500/8270 images\n",
            "   Processed 2600/8270 images\n",
            "   Processed 2700/8270 images\n",
            "   Processed 2800/8270 images\n",
            "   Processed 2900/8270 images\n",
            "   Processed 3000/8270 images\n",
            "   Processed 3100/8270 images\n",
            "   Processed 3200/8270 images\n",
            "   Processed 3300/8270 images\n",
            "   Processed 3400/8270 images\n",
            "   Processed 3500/8270 images\n",
            "   Processed 3600/8270 images\n",
            "   Processed 3700/8270 images\n",
            "   Processed 3800/8270 images\n",
            "   Processed 3900/8270 images\n",
            "   Processed 4000/8270 images\n",
            "   Processed 4100/8270 images\n",
            "   Processed 4200/8270 images\n",
            "   Processed 4300/8270 images\n",
            "   Processed 4400/8270 images\n",
            "   Processed 4500/8270 images\n",
            "   Processed 4600/8270 images\n",
            "   Processed 4700/8270 images\n",
            "   Processed 4800/8270 images\n",
            "   Processed 4900/8270 images\n",
            "   Processed 5000/8270 images\n",
            "   Processed 5100/8270 images\n",
            "   Processed 5200/8270 images\n",
            "   Processed 5300/8270 images\n",
            "   Processed 5400/8270 images\n",
            "   Processed 5500/8270 images\n",
            "   Processed 5600/8270 images\n",
            "   Processed 5700/8270 images\n",
            "   Processed 5800/8270 images\n",
            "   Processed 5900/8270 images\n",
            "   Processed 6000/8270 images\n",
            "   Processed 6100/8270 images\n",
            "   Processed 6200/8270 images\n",
            "   Processed 6300/8270 images\n",
            "   Processed 6400/8270 images\n",
            "   Processed 6500/8270 images\n",
            "   Processed 6600/8270 images\n",
            "   Processed 6700/8270 images\n",
            "   Processed 6800/8270 images\n",
            "   Processed 6900/8270 images\n",
            "   Processed 7000/8270 images\n",
            "   Processed 7100/8270 images\n",
            "   Processed 7200/8270 images\n",
            "   Processed 7300/8270 images\n",
            "   Processed 7400/8270 images\n",
            "   Processed 7500/8270 images\n",
            "   Processed 7600/8270 images\n",
            "   Processed 7700/8270 images\n",
            "   Processed 7800/8270 images\n",
            "   Processed 7900/8270 images\n",
            "   Processed 8000/8270 images\n",
            "   Processed 8100/8270 images\n",
            "   Processed 8200/8270 images\n",
            "âœ… Inference completed\n",
            "   Average inference time: 13.43ms per image\n",
            "\n",
            "ğŸ“Š Calculating evaluation metrics...\n",
            "âœ… Metrics calculated\n",
            "\n",
            "ğŸ¨ Generating evaluation visualizations...\n",
            "   ğŸ“Š Confusion matrix saved: outputs/yolo11_evaluation/visualizations/confusion_matrix_yolo11.png\n",
            "   ğŸ“Š Per-class metrics saved: outputs/yolo11_evaluation/visualizations/per_class_metrics_yolo11.png\n",
            "   ğŸ“Š Classification report saved: outputs/yolo11_evaluation/visualizations/classification_report_yolo11.png\n",
            "âœ… Visualizations saved to: outputs/yolo11_evaluation/visualizations\n",
            "ğŸ“ Evaluation results saved: outputs/yolo11_evaluation/results/yolo11_evaluation_20250901_065542.json\n",
            "\n",
            "======================================================================\n",
            "YOLO11 EMOTION DETECTION - EVALUATION SUMMARY\n",
            "======================================================================\n",
            "ğŸ¤– Model: yolo11_early_fusion_20250901_061809.pt\n",
            "ğŸ“Š Modality: rgb_only\n",
            "ğŸ¯ Confidence threshold: 0.25\n",
            "\n",
            "ğŸ“‚ Dataset:\n",
            "   Total images: 8270\n",
            "   Total faces: 8270\n",
            "\n",
            "ğŸ¯ Classification Performance:\n",
            "   Accuracy:  0.991\n",
            "   Precision: 0.991\n",
            "   Recall:    0.991\n",
            "   F1-Score:  0.991\n",
            "\n",
            "ğŸ” Detection Performance:\n",
            "   Precision: 0.991\n",
            "   Recall:    0.991\n",
            "   F1-Score:  0.991\n",
            "   True Positives:  8195\n",
            "   False Positives: 75\n",
            "   False Negatives: 75\n",
            "\n",
            "â±ï¸ Inference Timing:\n",
            "   Mean time:   13.43ms\n",
            "   Median time: 13.17ms\n",
            "   95th percentile: 14.43ms\n",
            "   FPS: 74.5\n",
            "\n",
            "ğŸ“ Visualizations: outputs/yolo11_evaluation/visualizations\n",
            "ğŸ“ Results: outputs/yolo11_evaluation/results\n",
            "======================================================================\n",
            "\n",
            "âœ… Evaluation completed successfully!\n",
            "ğŸ“Š Results saved to: outputs/yolo11_evaluation/\n"
          ]
        }
      ],
      "source": [
        "!python main_yolo11.py --evaluate --model models/yolo11_early_fusion_20250901_061809.pt --test-data yolo_early_fusion_dataset/test --conf 0.25"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NI0FCA1ghTLU",
        "outputId": "d363015c-7cc1-4077-ec44-e414030e9b2a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Emotion distribution in dataset:\n",
            "  angry: 7795\n",
            "  disgusted: 2208\n",
            "  fearful: 3460\n",
            "  happy: 12058\n",
            "  neutral: 1030\n",
            "  sad: 8827\n",
            "  surprised: 5992\n",
            "Total emotions parsed: 41370\n",
            "Unique emotions: ['angry', 'disgusted', 'fearful', 'happy', 'neutral', 'sad', 'surprised']\n"
          ]
        }
      ],
      "source": [
        "# import os\n",
        "# from collections import Counter\n",
        "\n",
        "# dataset_path = \"/content/drive/MyDrive/Data\"\n",
        "# emotions = []\n",
        "\n",
        "# valid_exts = ('.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.tif')\n",
        "\n",
        "# for root, dirs, files in os.walk(dataset_path):\n",
        "#     for file in files:\n",
        "#         if file.lower().endswith(valid_exts):\n",
        "#             file_lower = file.lower()\n",
        "#             if 'angry' in file_lower:\n",
        "#                 emotions.append('angry')\n",
        "#             elif 'happy' in file_lower:\n",
        "#                 emotions.append('happy')\n",
        "#             elif 'sad' in file_lower:\n",
        "#                 emotions.append('sad')\n",
        "#             elif 'surprise' in file_lower:\n",
        "#                 emotions.append('surprised')\n",
        "#             elif 'neutral' in file_lower:\n",
        "#                 emotions.append('neutral')\n",
        "#             elif 'fear' in file_lower:\n",
        "#                 emotions.append('fearful')\n",
        "#             elif 'disgust' in file_lower:\n",
        "#                 emotions.append('disgusted')\n",
        "\n",
        "# emotion_counts = Counter(emotions)\n",
        "\n",
        "# print('Emotion distribution in dataset:')\n",
        "# for emotion, count in sorted(emotion_counts.items()):\n",
        "#     print(f'  {emotion}: {count}')\n",
        "# print(f'Total emotions parsed: {len(emotions)}')\n",
        "# print(f'Unique emotions: {list(sorted(emotion_counts.keys()))}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AzhpPQ4fkSjC"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}