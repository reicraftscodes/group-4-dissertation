{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fWIos2RJfHsY",
        "outputId": "c7ce190e-342a-4457-a0dc-6dcba10459cf"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/Dissertation/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PRV5gtYDfJPn",
        "outputId": "08321afb-1678-4c09-840b-49bbe1d06487"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Dissertation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "collapsed": true,
        "id": "R_Z2uGEYfMMo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "SgAY-FUwefGy"
      },
      "outputs": [],
      "source": [
        "# Google Colab Unit Tests for Multimodal ViT Models\n",
        "# Run this in a Colab cell after importing your model classes\n",
        "\n",
        "# Suppress warnings for cleaner output\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "class TestViTForFER(unittest.TestCase):\n",
        "    \"\"\"Unit tests for ViTForFER model\"\"\"\n",
        "\n",
        "    def setUp(self):\n",
        "        \"\"\"Set up test fixtures before each test method.\"\"\"\n",
        "        self.batch_size = 2\n",
        "        self.num_classes = 7\n",
        "        self.pixel_values = torch.randn(self.batch_size, 3, 224, 224)\n",
        "        self.labels = torch.randint(0, self.num_classes, (self.batch_size,))\n",
        "\n",
        "    def test_initialization_default(self):\n",
        "        \"\"\"Test default initialization\"\"\"\n",
        "        model = ViTForFER()\n",
        "        self.assertEqual(model.num_classes, 7)\n",
        "        self.assertEqual(model.dropout_rate, 0.1)\n",
        "        self.assertFalse(model.freeze_backbone)\n",
        "\n",
        "    def test_initialization_custom(self):\n",
        "        \"\"\"Test custom initialization\"\"\"\n",
        "        model = ViTForFER(\n",
        "            num_classes=5,\n",
        "            dropout_rate=0.2,\n",
        "            freeze_backbone=True\n",
        "        )\n",
        "        self.assertEqual(model.num_classes, 5)\n",
        "        self.assertEqual(model.dropout_rate, 0.2)\n",
        "        self.assertTrue(model.freeze_backbone)\n",
        "\n",
        "    def test_config_setup(self):\n",
        "        \"\"\"Test model configuration\"\"\"\n",
        "        model = ViTForFER()\n",
        "        self.assertEqual(len(model.config.id2label), 7)\n",
        "        self.assertIn(\"happy\", model.config.id2label.values())\n",
        "        self.assertIn(\"angry\", model.config.id2label.values())\n",
        "\n",
        "\n",
        "    def test_forward_pass_with_labels(self):\n",
        "        \"\"\"Test forward pass with labels\"\"\"\n",
        "        model = ViTForFER()\n",
        "        outputs = model(self.pixel_values, self.labels)\n",
        "\n",
        "        self.assertIn('logits', outputs)\n",
        "        self.assertIsNotNone(outputs['loss'])\n",
        "        self.assertIsInstance(outputs['loss'], torch.Tensor)\n",
        "        self.assertGreaterEqual(outputs['loss'].item(), 0)\n",
        "\n",
        "    def test_feature_extraction(self):\n",
        "        \"\"\"Test feature extraction\"\"\"\n",
        "        model = ViTForFER()\n",
        "        features = model.get_features(self.pixel_values)\n",
        "\n",
        "        expected_shape = (self.batch_size, model.config.hidden_size)\n",
        "        self.assertEqual(features.shape, expected_shape)\n",
        "\n",
        "    def test_attention_weights(self):\n",
        "        \"\"\"Test attention weight extraction\"\"\"\n",
        "        model = ViTForFER()\n",
        "        attention_weights = model.get_attention_weights(self.pixel_values)\n",
        "\n",
        "        self.assertIsNotNone(attention_weights)\n",
        "        self.assertEqual(len(attention_weights.shape), 4)\n",
        "        self.assertEqual(attention_weights.shape[0], self.batch_size)\n",
        "\n",
        "    def test_freeze_unfreeze(self):\n",
        "        \"\"\"Test backbone freezing and unfreezing\"\"\"\n",
        "        model = ViTForFER(freeze_backbone=True)\n",
        "\n",
        "        # Check frozen state\n",
        "        backbone_frozen = all(not p.requires_grad for p in model.vit.vit.parameters())\n",
        "        self.assertTrue(backbone_frozen)\n",
        "\n",
        "        # Unfreeze and test\n",
        "        model.unfreeze_backbone()\n",
        "        backbone_unfrozen = all(p.requires_grad for p in model.vit.vit.parameters())\n",
        "        self.assertTrue(backbone_unfrozen)\n",
        "        self.assertFalse(model.freeze_backbone)\n",
        "\n",
        "    def test_model_info(self):\n",
        "        \"\"\"Test model information extraction\"\"\"\n",
        "        model = ViTForFER(num_classes=5, dropout_rate=0.15)\n",
        "        info = model.get_model_info()\n",
        "\n",
        "        required_keys = [\n",
        "            'model_name', 'num_classes', 'total_parameters', 'trainable_parameters',\n",
        "            'freeze_backbone', 'dropout_rate', 'image_size', 'patch_size',\n",
        "            'hidden_size', 'num_attention_heads', 'num_hidden_layers'\n",
        "        ]\n",
        "\n",
        "        for key in required_keys:\n",
        "            self.assertIn(key, info)\n",
        "\n",
        "        self.assertEqual(info['num_classes'], 5)\n",
        "        self.assertEqual(info['dropout_rate'], 0.15)\n",
        "        self.assertGreater(info['total_parameters'], 0)\n",
        "        self.assertLessEqual(info['trainable_parameters'], info['total_parameters'])\n",
        "\n",
        "\n",
        "class TestEarlyFusionViT(unittest.TestCase):\n",
        "    \"\"\"Unit tests for EarlyFusionViT model\"\"\"\n",
        "\n",
        "    def setUp(self):\n",
        "        \"\"\"Set up test fixtures\"\"\"\n",
        "        self.batch_size = 2\n",
        "        self.rgb_images = torch.randn(self.batch_size, 3, 224, 224)\n",
        "        self.thermal_images = torch.randn(self.batch_size, 3, 224, 224)\n",
        "        self.labels = torch.randint(0, 7, (self.batch_size,))\n",
        "\n",
        "    def test_initialization_concat(self):\n",
        "        \"\"\"Test concat fusion initialization\"\"\"\n",
        "        model = EarlyFusionViT(fusion_type=\"concat\")\n",
        "        self.assertEqual(model.input_channels, 6)\n",
        "        self.assertEqual(model.fusion_type, \"concat\")\n",
        "\n",
        "    def test_initialization_add(self):\n",
        "        \"\"\"Test add fusion initialization\"\"\"\n",
        "        model = EarlyFusionViT(fusion_type=\"add\")\n",
        "        self.assertEqual(model.input_channels, 3)\n",
        "        self.assertEqual(model.fusion_type, \"add\")\n",
        "\n",
        "    def test_forward_pass_concat(self):\n",
        "        \"\"\"Test forward pass with concat fusion\"\"\"\n",
        "        model = EarlyFusionViT(fusion_type=\"concat\")\n",
        "        outputs = model(self.rgb_images, self.thermal_images, self.labels)\n",
        "\n",
        "        self.assertIn('logits', outputs)\n",
        "        self.assertEqual(outputs['logits'].shape, (self.batch_size, 7))\n",
        "        self.assertIsNotNone(outputs['loss'])\n",
        "\n",
        "    def test_forward_pass_add(self):\n",
        "        \"\"\"Test forward pass with add fusion\"\"\"\n",
        "        model = EarlyFusionViT(fusion_type=\"add\")\n",
        "        outputs = model(self.rgb_images, self.thermal_images, self.labels)\n",
        "\n",
        "        self.assertIn('logits', outputs)\n",
        "        self.assertEqual(outputs['logits'].shape, (self.batch_size, 7))\n",
        "        self.assertIsNotNone(outputs['loss'])\n",
        "\n",
        "    def test_freeze_functionality(self):\n",
        "        \"\"\"Test freeze/unfreeze functionality\"\"\"\n",
        "        model = EarlyFusionViT(freeze_backbone=True)\n",
        "\n",
        "        # Check frozen\n",
        "        backbone_frozen = all(not p.requires_grad for p in model.vit.parameters())\n",
        "        self.assertTrue(backbone_frozen)\n",
        "\n",
        "        # Unfreeze\n",
        "        model.unfreeze_backbone()\n",
        "        backbone_unfrozen = all(p.requires_grad for p in model.vit.parameters())\n",
        "        self.assertTrue(backbone_unfrozen)\n",
        "\n",
        "\n",
        "class TestLateFusionViT(unittest.TestCase):\n",
        "    \"\"\"Unit tests for LateFusionViT model\"\"\"\n",
        "\n",
        "    def setUp(self):\n",
        "        \"\"\"Set up test fixtures\"\"\"\n",
        "        self.batch_size = 2\n",
        "        self.rgb_images = torch.randn(self.batch_size, 3, 224, 224)\n",
        "        self.thermal_images = torch.randn(self.batch_size, 3, 224, 224)\n",
        "        self.labels = torch.randint(0, 7, (self.batch_size,))\n",
        "\n",
        "    def test_initialization_feature_fusion(self):\n",
        "        \"\"\"Test feature-level fusion initialization\"\"\"\n",
        "        model = LateFusionViT(fusion_type=\"concat\", fusion_layer=\"feature\")\n",
        "        self.assertTrue(hasattr(model, 'classifier'))\n",
        "        self.assertTrue(hasattr(model, 'rgb_vit'))\n",
        "        self.assertTrue(hasattr(model, 'thermal_vit'))\n",
        "\n",
        "    def test_initialization_prediction_fusion(self):\n",
        "        \"\"\"Test prediction-level fusion initialization\"\"\"\n",
        "        model = LateFusionViT(fusion_type=\"concat\", fusion_layer=\"prediction\")\n",
        "        self.assertTrue(hasattr(model, 'rgb_classifier'))\n",
        "        self.assertTrue(hasattr(model, 'thermal_classifier'))\n",
        "\n",
        "    def test_initialization_attention_fusion(self):\n",
        "        \"\"\"Test attention fusion initialization\"\"\"\n",
        "        model = LateFusionViT(fusion_type=\"attention\", fusion_layer=\"feature\")\n",
        "        self.assertTrue(hasattr(model, 'attention_fusion'))\n",
        "\n",
        "    def test_forward_pass_feature_level(self):\n",
        "        \"\"\"Test forward pass with feature-level fusion\"\"\"\n",
        "        fusion_configs = [\n",
        "            {\"fusion_type\": \"concat\", \"fusion_layer\": \"feature\"},\n",
        "            {\"fusion_type\": \"add\", \"fusion_layer\": \"feature\"},\n",
        "            {\"fusion_type\": \"attention\", \"fusion_layer\": \"feature\"},\n",
        "        ]\n",
        "\n",
        "        for config in fusion_configs:\n",
        "            with self.subTest(config=config):\n",
        "                model = LateFusionViT(**config)\n",
        "                outputs = model(self.rgb_images, self.thermal_images, self.labels)\n",
        "\n",
        "                self.assertIn('logits', outputs)\n",
        "                self.assertEqual(outputs['logits'].shape, (self.batch_size, 7))\n",
        "                self.assertIsNotNone(outputs['loss'])\n",
        "                self.assertIn('rgb_features', outputs)\n",
        "                self.assertIn('thermal_features', outputs)\n",
        "\n",
        "    def test_forward_pass_prediction_level(self):\n",
        "        \"\"\"Test forward pass with prediction-level fusion\"\"\"\n",
        "        fusion_configs = [\n",
        "            {\"fusion_type\": \"concat\", \"fusion_layer\": \"prediction\"},\n",
        "            {\"fusion_type\": \"add\", \"fusion_layer\": \"prediction\"},\n",
        "            {\"fusion_type\": \"attention\", \"fusion_layer\": \"prediction\"},\n",
        "        ]\n",
        "\n",
        "        for config in fusion_configs:\n",
        "            with self.subTest(config=config):\n",
        "                model = LateFusionViT(**config)\n",
        "                outputs = model(self.rgb_images, self.thermal_images, self.labels)\n",
        "\n",
        "                self.assertIn('logits', outputs)\n",
        "                self.assertEqual(outputs['logits'].shape, (self.batch_size, 7))\n",
        "                self.assertIsNotNone(outputs['loss'])\n",
        "\n",
        "\n",
        "class TestModelFactory(unittest.TestCase):\n",
        "    \"\"\"Unit tests for create_multimodal_vit_model function\"\"\"\n",
        "\n",
        "    def test_create_rgb_model(self):\n",
        "        \"\"\"Test RGB model creation\"\"\"\n",
        "        model = create_multimodal_vit_model(mode='rgb')\n",
        "        self.assertIsInstance(model, ViTForFER)\n",
        "\n",
        "    def test_create_thermal_model(self):\n",
        "        \"\"\"Test thermal model creation\"\"\"\n",
        "        model = create_multimodal_vit_model(mode='thermal')\n",
        "        self.assertIsInstance(model, ViTForFER)\n",
        "\n",
        "    def test_create_early_fusion_model(self):\n",
        "        \"\"\"Test early fusion model creation\"\"\"\n",
        "        model = create_multimodal_vit_model(\n",
        "            mode='combined',\n",
        "            fusion_strategy='early',\n",
        "            fusion_type='concat'\n",
        "        )\n",
        "        self.assertIsInstance(model, EarlyFusionViT)\n",
        "\n",
        "    def test_create_late_fusion_model(self):\n",
        "        \"\"\"Test late fusion model creation\"\"\"\n",
        "        model = create_multimodal_vit_model(\n",
        "            mode='combined',\n",
        "            fusion_strategy='late',\n",
        "            fusion_type='concat',\n",
        "            fusion_layer='feature'\n",
        "        )\n",
        "        self.assertIsInstance(model, LateFusionViT)\n",
        "\n",
        "    def test_invalid_mode(self):\n",
        "        \"\"\"Test invalid mode raises error\"\"\"\n",
        "        with self.assertRaises(ValueError):\n",
        "            create_multimodal_vit_model(mode='invalid')\n",
        "\n",
        "\n",
        "class TestOptimizerAndScheduler(unittest.TestCase):\n",
        "    \"\"\"Unit tests for optimizer and scheduler creation\"\"\"\n",
        "\n",
        "    def test_adamw_optimizer(self):\n",
        "        \"\"\"Test AdamW optimizer creation\"\"\"\n",
        "        model = ViTForFER()\n",
        "        optimizer, scheduler = get_optimizer_and_scheduler(\n",
        "            model=model,\n",
        "            learning_rate=1e-4,\n",
        "            optimizer_type=\"adamw\"\n",
        "        )\n",
        "\n",
        "        self.assertIsInstance(optimizer, torch.optim.AdamW)\n",
        "        self.assertEqual(len(optimizer.param_groups), 2)\n",
        "\n",
        "    def test_sgd_optimizer(self):\n",
        "        \"\"\"Test SGD optimizer creation\"\"\"\n",
        "        model = ViTForFER()\n",
        "        optimizer, scheduler = get_optimizer_and_scheduler(\n",
        "            model=model,\n",
        "            optimizer_type=\"sgd\"\n",
        "        )\n",
        "\n",
        "        self.assertIsInstance(optimizer, torch.optim.SGD)\n",
        "        self.assertEqual(len(optimizer.param_groups), 2)\n",
        "\n",
        "\n",
        "class TestGradientFlow(unittest.TestCase):\n",
        "    \"\"\"Unit tests for gradient flow\"\"\"\n",
        "\n",
        "    def test_gradient_flow_unfrozen(self):\n",
        "        \"\"\"Test gradient flow with unfrozen backbone\"\"\"\n",
        "        model = ViTForFER()\n",
        "        batch_size = 2\n",
        "        pixel_values = torch.randn(batch_size, 3, 224, 224, requires_grad=True)\n",
        "        labels = torch.randint(0, 7, (batch_size,))\n",
        "\n",
        "        outputs = model(pixel_values, labels)\n",
        "        loss = outputs['loss']\n",
        "        loss.backward()\n",
        "\n",
        "        # Check gradients exist\n",
        "        has_gradients = False\n",
        "        for param in model.parameters():\n",
        "            if param.requires_grad and param.grad is not None:\n",
        "                has_gradients = True\n",
        "                break\n",
        "\n",
        "        self.assertTrue(has_gradients)\n",
        "\n",
        "    def test_gradient_flow_frozen(self):\n",
        "        \"\"\"Test gradient flow with frozen backbone\"\"\"\n",
        "        model = ViTForFER(freeze_backbone=True)\n",
        "        batch_size = 2\n",
        "        pixel_values = torch.randn(batch_size, 3, 224, 224)\n",
        "        labels = torch.randint(0, 7, (batch_size,))\n",
        "\n",
        "        outputs = model(pixel_values, labels)\n",
        "        loss = outputs['loss']\n",
        "        loss.backward()\n",
        "\n",
        "        # Check only classifier has gradients\n",
        "        for name, param in model.named_parameters():\n",
        "            if param.requires_grad:\n",
        "                self.assertIsNotNone(param.grad)\n",
        "                self.assertIn('classifier', name)\n",
        "\n",
        "\n",
        "class TestInputValidation(unittest.TestCase):\n",
        "    \"\"\"Unit tests for input validation\"\"\"\n",
        "\n",
        "    def test_different_batch_sizes(self):\n",
        "        \"\"\"Test different batch sizes\"\"\"\n",
        "        model = ViTForFER()\n",
        "\n",
        "        for batch_size in [1, 2, 4, 8]:\n",
        "            with self.subTest(batch_size=batch_size):\n",
        "                pixel_values = torch.randn(batch_size, 3, 224, 224)\n",
        "                outputs = model(pixel_values)\n",
        "                self.assertEqual(outputs['logits'].shape[0], batch_size)\n",
        "\n",
        "    def test_multimodal_consistency(self):\n",
        "        \"\"\"Test multimodal input consistency\"\"\"\n",
        "        batch_size = 2\n",
        "        rgb_images = torch.randn(batch_size, 3, 224, 224)\n",
        "        thermal_images = torch.randn(batch_size, 3, 224, 224)\n",
        "        labels = torch.randint(0, 7, (batch_size,))\n",
        "\n",
        "        early_concat = EarlyFusionViT(fusion_type=\"concat\")\n",
        "        early_add = EarlyFusionViT(fusion_type=\"add\")\n",
        "\n",
        "        outputs_concat = early_concat(rgb_images, thermal_images, labels)\n",
        "        outputs_add = early_add(rgb_images, thermal_images, labels)\n",
        "\n",
        "        # Different fusion should produce different outputs\n",
        "        self.assertFalse(torch.allclose(outputs_concat['logits'], outputs_add['logits'], atol=1e-6))\n",
        "\n",
        "        # But same shape\n",
        "        self.assertEqual(outputs_concat['logits'].shape, outputs_add['logits'].shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Colab-friendly test runner\n",
        "def run_tests_in_colab():\n",
        "    \"\"\"\n",
        "    Run all tests in Google Colab with nice formatting\n",
        "    \"\"\"\n",
        "    print(\"Starting Multimodal ViT Unit Tests\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Capture test output\n",
        "    test_output = StringIO()\n",
        "    runner = unittest.TextTestRunner(stream=test_output, verbosity=2)\n",
        "\n",
        "    # Create test suite\n",
        "    test_classes = [\n",
        "        TestViTForFER,\n",
        "        TestEarlyFusionViT,\n",
        "        TestLateFusionViT,\n",
        "        TestModelFactory,\n",
        "        TestOptimizerAndScheduler,\n",
        "        TestGradientFlow,\n",
        "        TestInputValidation\n",
        "    ]\n",
        "\n",
        "    total_tests = 0\n",
        "    total_failures = 0\n",
        "    total_errors = 0\n",
        "\n",
        "    for test_class in test_classes:\n",
        "        print(f\"\\nRunning {test_class.__name__}...\")\n",
        "        suite = unittest.TestLoader().loadTestsFromTestCase(test_class)\n",
        "        result = runner.run(suite)\n",
        "\n",
        "        total_tests += result.testsRun\n",
        "        total_failures += len(result.failures)\n",
        "        total_errors += len(result.errors)\n",
        "\n",
        "        if result.failures:\n",
        "            print(f\"{len(result.failures)} failures\")\n",
        "            for test, traceback in result.failures:\n",
        "                print(f\"   FAIL: {test}\")\n",
        "\n",
        "        if result.errors:\n",
        "            print(f\"💥 {len(result.errors)} errors\")\n",
        "            for test, traceback in result.errors:\n",
        "                print(f\"   ERROR: {test}\")\n",
        "\n",
        "        if not result.failures and not result.errors:\n",
        "            print(f\" All tests passed!\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(f\" FINAL RESULTS:\")\n",
        "    print(f\"   Total Tests: {total_tests}\")\n",
        "    print(f\"   Passed: {total_tests - total_failures - total_errors}\")\n",
        "    print(f\"   Failed: {total_failures}\")\n",
        "    print(f\"   Errors: {total_errors}\")\n",
        "\n",
        "    if total_failures == 0 and total_errors == 0:\n",
        "        print(\" ==== ALL TESTS PASSED! ====\")\n",
        "    else:\n",
        "        print(f\"⚠️  {total_failures + total_errors} TESTS FAILED\")\n",
        "\n",
        "    return total_failures == 0 and total_errors == 0"
      ],
      "metadata": {
        "id": "H86klMSwewbB"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Quick test function for individual testing\n",
        "def quick_test():\n",
        "    \"\"\"Run a quick smoke test\"\"\"\n",
        "    print(\"🔥 Running Quick Smoke Test...\")\n",
        "\n",
        "    try:\n",
        "        # Test basic model creation\n",
        "        model = ViTForFER()\n",
        "        print(\"✅ ViTForFER created successfully\")\n",
        "\n",
        "        # Test basic forward pass\n",
        "        x = torch.randn(1, 3, 224, 224)\n",
        "        outputs = model(x)\n",
        "        print(f\"✅ Forward pass successful, output shape: {outputs['logits'].shape}\")\n",
        "\n",
        "        # Test multimodal model\n",
        "        multimodal_model = create_multimodal_vit_model(mode='combined', fusion_strategy='early')\n",
        "        print(\"✅ Multimodal model created successfully\")\n",
        "\n",
        "        rgb = torch.randn(1, 3, 224, 224)\n",
        "        thermal = torch.randn(1, 3, 224, 224)\n",
        "        multimodal_outputs = multimodal_model(rgb, thermal)\n",
        "        print(f\"✅ Multimodal forward pass successful, output shape: {multimodal_outputs['logits'].shape}\")\n",
        "\n",
        "        print(\"🎉 Quick test completed successfully!\")\n",
        "        return True\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Quick test failed: {str(e)}\")\n",
        "        return False"
      ],
      "metadata": {
        "id": "FPmM9ymLgAQp"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Usage instructions for Colab\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"\"\"\n",
        "    📚 How to use these tests in Google Colab:\n",
        "\n",
        "    1. First, make sure your model classes are imported:\n",
        "       from model import create_multimodal_vit_model, get_optimizer_and_scheduler, ViTForFER, EarlyFusionViT, LateFusionViT\n",
        "\n",
        "    2. Run a quick test:\n",
        "       quick_test()\n",
        "\n",
        "    3. Run all unit tests:\n",
        "       run_tests_in_colab()\n",
        "\n",
        "    4. Run specific test class:\n",
        "       suite = unittest.TestLoader().loadTestsFromTestCase(TestViTForFER)\n",
        "       runner = unittest.TextTestRunner(verbosity=2)\n",
        "       runner.run(suite)\n",
        "    \"\"\")\n",
        "\n",
        "    # Uncomment to run tests automatically\n",
        "    # quick_test()\n",
        "    run_tests_in_colab()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MOTGZf19e3uf",
        "outputId": "48850792-2fc0-406e-c024-fb6c471b3f76"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    📚 How to use these tests in Google Colab:\n",
            "\n",
            "    1. First, make sure your model classes are imported:\n",
            "       from model import create_multimodal_vit_model, get_optimizer_and_scheduler, ViTForFER, EarlyFusionViT, LateFusionViT\n",
            "\n",
            "    2. Run a quick test:\n",
            "       quick_test()\n",
            "\n",
            "    3. Run all unit tests:\n",
            "       run_tests_in_colab()\n",
            "\n",
            "    4. Run specific test class:\n",
            "       suite = unittest.TestLoader().loadTestsFromTestCase(TestViTForFER)\n",
            "       runner = unittest.TextTestRunner(verbosity=2)\n",
            "       runner.run(suite)\n",
            "    \n",
            "Starting Multimodal ViT Unit Tests\n",
            "============================================================\n",
            "\n",
            "Running TestViTForFER...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Fast image processor class <class 'transformers.models.vit.image_processing_vit_fast.ViTImageProcessorFast'> is available for this model. Using slow image processor class. To use the fast image processor class set `use_fast=True`.\n",
            "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Fast image processor class <class 'transformers.models.vit.image_processing_vit_fast.ViTImageProcessorFast'> is available for this model. Using slow image processor class. To use the fast image processor class set `use_fast=True`.\n",
            "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Fast image processor class <class 'transformers.models.vit.image_processing_vit_fast.ViTImageProcessorFast'> is available for this model. Using slow image processor class. To use the fast image processor class set `use_fast=True`.\n",
            "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Fast image processor class <class 'transformers.models.vit.image_processing_vit_fast.ViTImageProcessorFast'> is available for this model. Using slow image processor class. To use the fast image processor class set `use_fast=True`.\n",
            "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Fast image processor class <class 'transformers.models.vit.image_processing_vit_fast.ViTImageProcessorFast'> is available for this model. Using slow image processor class. To use the fast image processor class set `use_fast=True`.\n",
            "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Fast image processor class <class 'transformers.models.vit.image_processing_vit_fast.ViTImageProcessorFast'> is available for this model. Using slow image processor class. To use the fast image processor class set `use_fast=True`.\n",
            "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Fast image processor class <class 'transformers.models.vit.image_processing_vit_fast.ViTImageProcessorFast'> is available for this model. Using slow image processor class. To use the fast image processor class set `use_fast=True`.\n",
            "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Fast image processor class <class 'transformers.models.vit.image_processing_vit_fast.ViTImageProcessorFast'> is available for this model. Using slow image processor class. To use the fast image processor class set `use_fast=True`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " All tests passed!\n",
            "\n",
            "Running TestEarlyFusionViT...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of ViTModel were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized because the shapes did not match:\n",
            "- embeddings.patch_embeddings.projection.weight: found shape torch.Size([768, 3, 16, 16]) in the checkpoint and torch.Size([768, 6, 16, 16]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of ViTModel were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized because the shapes did not match:\n",
            "- embeddings.patch_embeddings.projection.weight: found shape torch.Size([768, 3, 16, 16]) in the checkpoint and torch.Size([768, 6, 16, 16]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of ViTModel were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized because the shapes did not match:\n",
            "- embeddings.patch_embeddings.projection.weight: found shape torch.Size([768, 3, 16, 16]) in the checkpoint and torch.Size([768, 6, 16, 16]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " All tests passed!\n",
            "\n",
            "Running TestLateFusionViT...\n",
            " All tests passed!\n",
            "\n",
            "Running TestModelFactory...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of ViTModel were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized because the shapes did not match:\n",
            "- embeddings.patch_embeddings.projection.weight: found shape torch.Size([768, 3, 16, 16]) in the checkpoint and torch.Size([768, 6, 16, 16]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Fast image processor class <class 'transformers.models.vit.image_processing_vit_fast.ViTImageProcessorFast'> is available for this model. Using slow image processor class. To use the fast image processor class set `use_fast=True`.\n",
            "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Fast image processor class <class 'transformers.models.vit.image_processing_vit_fast.ViTImageProcessorFast'> is available for this model. Using slow image processor class. To use the fast image processor class set `use_fast=True`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " All tests passed!\n",
            "\n",
            "Running TestOptimizerAndScheduler...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Fast image processor class <class 'transformers.models.vit.image_processing_vit_fast.ViTImageProcessorFast'> is available for this model. Using slow image processor class. To use the fast image processor class set `use_fast=True`.\n",
            "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Fast image processor class <class 'transformers.models.vit.image_processing_vit_fast.ViTImageProcessorFast'> is available for this model. Using slow image processor class. To use the fast image processor class set `use_fast=True`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " All tests passed!\n",
            "\n",
            "Running TestGradientFlow...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Fast image processor class <class 'transformers.models.vit.image_processing_vit_fast.ViTImageProcessorFast'> is available for this model. Using slow image processor class. To use the fast image processor class set `use_fast=True`.\n",
            "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Fast image processor class <class 'transformers.models.vit.image_processing_vit_fast.ViTImageProcessorFast'> is available for this model. Using slow image processor class. To use the fast image processor class set `use_fast=True`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " All tests passed!\n",
            "\n",
            "Running TestInputValidation...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Fast image processor class <class 'transformers.models.vit.image_processing_vit_fast.ViTImageProcessorFast'> is available for this model. Using slow image processor class. To use the fast image processor class set `use_fast=True`.\n",
            "Some weights of ViTModel were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized because the shapes did not match:\n",
            "- embeddings.patch_embeddings.projection.weight: found shape torch.Size([768, 3, 16, 16]) in the checkpoint and torch.Size([768, 6, 16, 16]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " All tests passed!\n",
            "\n",
            "============================================================\n",
            " FINAL RESULTS:\n",
            "   Total Tests: 29\n",
            "   Passed: 29\n",
            "   Failed: 0\n",
            "   Errors: 0\n",
            " ==== ALL TESTS PASSED! ====\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0JwaZFRdMC1S"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}